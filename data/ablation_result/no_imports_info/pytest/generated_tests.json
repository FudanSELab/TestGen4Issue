[
    {
        "repo": "pytest-dev/pytest",
        "instance_id": "pytest-dev__pytest-11148",
        "base_commit": "2f7415cfbc4b6ca62f9013f1abd27136f46b9653",
        "patch": "diff --git a/src/_pytest/pathlib.py b/src/_pytest/pathlib.py\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -523,6 +523,8 @@ def import_path(\n \n     if mode is ImportMode.importlib:\n         module_name = module_name_from_path(path, root)\n+        with contextlib.suppress(KeyError):\n+            return sys.modules[module_name]\n \n         for meta_importer in sys.meta_path:\n             spec = meta_importer.find_spec(module_name, [str(path.parent)])\n",
        "test_patch": "diff --git a/testing/acceptance_test.py b/testing/acceptance_test.py\n--- a/testing/acceptance_test.py\n+++ b/testing/acceptance_test.py\n@@ -1315,3 +1315,38 @@ def test_stuff():\n     )\n     res = pytester.runpytest()\n     res.stdout.fnmatch_lines([\"*Did you mean to use `assert` instead of `return`?*\"])\n+\n+\n+def test_doctest_and_normal_imports_with_importlib(pytester: Pytester) -> None:\n+    \"\"\"\n+    Regression test for #10811: previously import_path with ImportMode.importlib would\n+    not return a module if already in sys.modules, resulting in modules being imported\n+    multiple times, which causes problems with modules that have import side effects.\n+    \"\"\"\n+    # Uses the exact reproducer form #10811, given it is very minimal\n+    # and illustrates the problem well.\n+    pytester.makepyfile(\n+        **{\n+            \"pmxbot/commands.py\": \"from . import logging\",\n+            \"pmxbot/logging.py\": \"\",\n+            \"tests/__init__.py\": \"\",\n+            \"tests/test_commands.py\": \"\"\"\n+                import importlib\n+                from pmxbot import logging\n+\n+                class TestCommands:\n+                    def test_boo(self):\n+                        assert importlib.import_module('pmxbot.logging') is logging\n+                \"\"\",\n+        }\n+    )\n+    pytester.makeini(\n+        \"\"\"\n+        [pytest]\n+        addopts=\n+            --doctest-modules\n+            --import-mode importlib\n+        \"\"\"\n+    )\n+    result = pytester.runpytest_subprocess()\n+    result.stdout.fnmatch_lines(\"*1 passed*\")\ndiff --git a/testing/test_pathlib.py b/testing/test_pathlib.py\n--- a/testing/test_pathlib.py\n+++ b/testing/test_pathlib.py\n@@ -7,6 +7,7 @@\n from types import ModuleType\n from typing import Any\n from typing import Generator\n+from typing import Iterator\n \n import pytest\n from _pytest.monkeypatch import MonkeyPatch\n@@ -282,29 +283,36 @@ def test_invalid_path(self, tmp_path: Path) -> None:\n             import_path(tmp_path / \"invalid.py\", root=tmp_path)\n \n     @pytest.fixture\n-    def simple_module(self, tmp_path: Path) -> Path:\n-        fn = tmp_path / \"_src/tests/mymod.py\"\n+    def simple_module(\n+        self, tmp_path: Path, request: pytest.FixtureRequest\n+    ) -> Iterator[Path]:\n+        name = f\"mymod_{request.node.name}\"\n+        fn = tmp_path / f\"_src/tests/{name}.py\"\n         fn.parent.mkdir(parents=True)\n         fn.write_text(\"def foo(x): return 40 + x\", encoding=\"utf-8\")\n-        return fn\n+        module_name = module_name_from_path(fn, root=tmp_path)\n+        yield fn\n+        sys.modules.pop(module_name, None)\n \n-    def test_importmode_importlib(self, simple_module: Path, tmp_path: Path) -> None:\n+    def test_importmode_importlib(\n+        self, simple_module: Path, tmp_path: Path, request: pytest.FixtureRequest\n+    ) -> None:\n         \"\"\"`importlib` mode does not change sys.path.\"\"\"\n         module = import_path(simple_module, mode=\"importlib\", root=tmp_path)\n         assert module.foo(2) == 42  # type: ignore[attr-defined]\n         assert str(simple_module.parent) not in sys.path\n         assert module.__name__ in sys.modules\n-        assert module.__name__ == \"_src.tests.mymod\"\n+        assert module.__name__ == f\"_src.tests.mymod_{request.node.name}\"\n         assert \"_src\" in sys.modules\n         assert \"_src.tests\" in sys.modules\n \n-    def test_importmode_twice_is_different_module(\n+    def test_remembers_previous_imports(\n         self, simple_module: Path, tmp_path: Path\n     ) -> None:\n-        \"\"\"`importlib` mode always returns a new module.\"\"\"\n+        \"\"\"`importlib` mode called remembers previous module (#10341, #10811).\"\"\"\n         module1 = import_path(simple_module, mode=\"importlib\", root=tmp_path)\n         module2 = import_path(simple_module, mode=\"importlib\", root=tmp_path)\n-        assert module1 is not module2\n+        assert module1 is module2\n \n     def test_no_meta_path_found(\n         self, simple_module: Path, monkeypatch: MonkeyPatch, tmp_path: Path\n@@ -317,6 +325,9 @@ def test_no_meta_path_found(\n         # mode='importlib' fails if no spec is found to load the module\n         import importlib.util\n \n+        # Force module to be re-imported.\n+        del sys.modules[module.__name__]\n+\n         monkeypatch.setattr(\n             importlib.util, \"spec_from_file_location\", lambda *args: None\n         )\n",
        "problem_statement": "Module imported twice under import-mode=importlib\nIn pmxbot/pmxbot@7f189ad, I'm attempting to switch pmxbot off of pkg_resources style namespace packaging to PEP 420 namespace packages. To do so, I've needed to switch to `importlib` for the `import-mode` and re-organize the tests to avoid import errors on the tests.\r\n\r\nYet even after working around these issues, the tests are failing when the effect of `core.initialize()` doesn't seem to have had any effect.\r\n\r\nInvestigating deeper, I see that initializer is executed and performs its actions (setting a class variable `pmxbot.logging.Logger.store`), but when that happens, there are two different versions of `pmxbot.logging` present, one in `sys.modules` and another found in `tests.unit.test_commands.logging`:\r\n\r\n```\r\n=========================================================================== test session starts ===========================================================================\r\nplatform darwin -- Python 3.11.1, pytest-7.2.0, pluggy-1.0.0\r\ncachedir: .tox/python/.pytest_cache\r\nrootdir: /Users/jaraco/code/pmxbot/pmxbot, configfile: pytest.ini\r\nplugins: black-0.3.12, mypy-0.10.3, jaraco.test-5.3.0, checkdocs-2.9.0, flake8-1.1.1, enabler-2.0.0, jaraco.mongodb-11.2.1, pmxbot-1122.14.3.dev13+g7f189ad\r\ncollected 421 items / 180 deselected / 241 selected                                                                                                                       \r\nrun-last-failure: rerun previous 240 failures (skipped 14 files)\r\n\r\ntests/unit/test_commands.py E\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> traceback >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n\r\ncls = <class 'tests.unit.test_commands.TestCommands'>\r\n\r\n    @classmethod\r\n    def setup_class(cls):\r\n        path = os.path.dirname(os.path.abspath(__file__))\r\n        configfile = os.path.join(path, 'testconf.yaml')\r\n        config = pmxbot.dictlib.ConfigDict.from_yaml(configfile)\r\n        cls.bot = core.initialize(config)\r\n>       logging.Logger.store.message(\"logged\", \"testrunner\", \"some text\")\r\nE       AttributeError: type object 'Logger' has no attribute 'store'\r\n\r\ntests/unit/test_commands.py:37: AttributeError\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> entering PDB >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> PDB post_mortem (IO-capturing turned off) >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n> /Users/jaraco/code/pmxbot/pmxbot/tests/unit/test_commands.py(37)setup_class()\r\n-> logging.Logger.store.message(\"logged\", \"testrunner\", \"some text\")\r\n(Pdb) logging.Logger\r\n<class 'pmxbot.logging.Logger'>\r\n(Pdb) logging\r\n<module 'pmxbot.logging' from '/Users/jaraco/code/pmxbot/pmxbot/pmxbot/logging.py'>\r\n(Pdb) import sys\r\n(Pdb) sys.modules['pmxbot.logging']\r\n<module 'pmxbot.logging' from '/Users/jaraco/code/pmxbot/pmxbot/pmxbot/logging.py'>\r\n(Pdb) sys.modules['pmxbot.logging'] is logging\r\nFalse\r\n```\r\n\r\nI haven't yet made a minimal reproducer, but I wanted to first capture this condition.\r\n\n",
        "hints_text": "In pmxbot/pmxbot@3adc54c, I've managed to pare down the project to a bare minimum reproducer. The issue only happens when `import-mode=importlib` and `doctest-modules` and one of the modules imports another module.\r\n\r\nThis issue may be related to (or same as) #10341.\r\n\r\nI think you'll agree this is pretty basic behavior that should be supported.\r\n\r\nI'm not even aware of a good workaround.\nHey @jaraco, thanks for the reproducer! \r\n\r\nI found the problem, will open a PR shortly.",
        "created_at": "2023-06-29T00:04:33Z",
        "version": "8.0",
        "FAIL_TO_PASS": "[\"testing/test_pathlib.py::TestImportPath::test_remembers_previous_imports\", \"testing/acceptance_test.py::test_doctest_and_normal_imports_with_importlib\"]",
        "PASS_TO_PASS": "[\"testing/acceptance_test.py::TestGeneralUsage::test_docstring_on_hookspec\", \"testing/acceptance_test.py::TestInvocationVariants::test_invoke_with_invalid_type\", \"testing/acceptance_test.py::TestInvocationVariants::test_invoke_plugin_api\", \"testing/acceptance_test.py::TestInvocationVariants::test_core_backward_compatibility\", \"testing/acceptance_test.py::TestInvocationVariants::test_has_plugin\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[*.py-foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[*.py-bar/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[test_*.py-foo/test_foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[tests/*.py-tests/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[/c/*.py-/c/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[/c/foo/*.py-/c/foo/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[tests/**/test*.py-tests/foo/test_foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[tests/**/doc/test*.py-tests/foo/bar/doc/test_foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching[tests/**/doc/**/test*.py-tests/foo/doc/bar/test_foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_matching_abspath\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[*.py-foo.pyc]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[*.py-foo/foo.pyc]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[tests/*.py-foo/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[/c/*.py-/d/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[/c/foo/*.py-/d/foo/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[tests/**/test*.py-tests/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[tests/**/test*.py-foo/test_foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[tests/**/doc/test*.py-tests/foo/bar/doc/foo.py]\", \"testing/test_pathlib.py::TestFNMatcherPort::test_not_matching[tests/**/doc/test*.py-tests/foo/bar/test_foo.py]\", \"testing/test_pathlib.py::TestImportPath::test_smoke_test\", \"testing/test_pathlib.py::TestImportPath::test_import_path_missing_file\", \"testing/test_pathlib.py::TestImportPath::test_renamed_dir_creates_mismatch\", \"testing/test_pathlib.py::TestImportPath::test_messy_name\", \"testing/test_pathlib.py::TestImportPath::test_dir\", \"testing/test_pathlib.py::TestImportPath::test_a\", \"testing/test_pathlib.py::TestImportPath::test_b\", \"testing/test_pathlib.py::TestImportPath::test_c\", \"testing/test_pathlib.py::TestImportPath::test_d\", \"testing/test_pathlib.py::TestImportPath::test_import_after\", \"testing/test_pathlib.py::TestImportPath::test_check_filepath_consistency\", \"testing/test_pathlib.py::TestImportPath::test_issue131_on__init__\", \"testing/test_pathlib.py::TestImportPath::test_ensuresyspath_append\", \"testing/test_pathlib.py::TestImportPath::test_invalid_path\", \"testing/test_pathlib.py::TestImportPath::test_importmode_importlib\", \"testing/test_pathlib.py::TestImportPath::test_no_meta_path_found\", \"testing/test_pathlib.py::test_resolve_package_path\", \"testing/test_pathlib.py::test_package_unimportable\", \"testing/test_pathlib.py::test_access_denied_during_cleanup\", \"testing/test_pathlib.py::test_long_path_during_cleanup\", \"testing/test_pathlib.py::test_get_extended_length_path_str\", \"testing/test_pathlib.py::test_suppress_error_removing_lock\", \"testing/test_pathlib.py::test_bestrelpath\", \"testing/test_pathlib.py::test_commonpath\", \"testing/test_pathlib.py::test_visit_ignores_errors\", \"testing/test_pathlib.py::TestImportLibMode::test_importmode_importlib_with_dataclass\", \"testing/test_pathlib.py::TestImportLibMode::test_importmode_importlib_with_pickle\", \"testing/test_pathlib.py::TestImportLibMode::test_importmode_importlib_with_pickle_separate_modules\", \"testing/test_pathlib.py::TestImportLibMode::test_module_name_from_path\", \"testing/test_pathlib.py::TestImportLibMode::test_insert_missing_modules\", \"testing/test_pathlib.py::TestImportLibMode::test_parent_contains_child_module_attribute\", \"testing/acceptance_test.py::TestGeneralUsage::test_config_error\", \"testing/acceptance_test.py::TestGeneralUsage::test_root_conftest_syntax_error\", \"testing/acceptance_test.py::TestGeneralUsage::test_early_hook_error_issue38_1\", \"testing/acceptance_test.py::TestGeneralUsage::test_early_hook_configure_error_issue38\", \"testing/acceptance_test.py::TestGeneralUsage::test_file_not_found\", \"testing/acceptance_test.py::TestGeneralUsage::test_file_not_found_unconfigure_issue143\", \"testing/acceptance_test.py::TestGeneralUsage::test_config_preparse_plugin_option\", \"testing/acceptance_test.py::TestGeneralUsage::test_early_load_setuptools_name[True]\", \"testing/acceptance_test.py::TestGeneralUsage::test_early_load_setuptools_name[False]\", \"testing/acceptance_test.py::TestGeneralUsage::test_assertion_rewrite[prepend]\", \"testing/acceptance_test.py::TestGeneralUsage::test_assertion_rewrite[append]\", \"testing/acceptance_test.py::TestGeneralUsage::test_assertion_rewrite[importlib]\", \"testing/acceptance_test.py::TestGeneralUsage::test_nested_import_error\", \"testing/acceptance_test.py::TestGeneralUsage::test_not_collectable_arguments\", \"testing/acceptance_test.py::TestGeneralUsage::test_better_reporting_on_conftest_load_failure\", \"testing/acceptance_test.py::TestGeneralUsage::test_early_skip\", \"testing/acceptance_test.py::TestGeneralUsage::test_issue88_initial_file_multinodes\", \"testing/acceptance_test.py::TestGeneralUsage::test_issue93_initialnode_importing_capturing\", \"testing/acceptance_test.py::TestGeneralUsage::test_conftest_printing_shows_if_error\", \"testing/acceptance_test.py::TestGeneralUsage::test_issue109_sibling_conftests_not_loaded\", \"testing/acceptance_test.py::TestGeneralUsage::test_directory_skipped\", \"testing/acceptance_test.py::TestGeneralUsage::test_multiple_items_per_collector_byid\", \"testing/acceptance_test.py::TestGeneralUsage::test_skip_on_generated_funcarg_id\", \"testing/acceptance_test.py::TestGeneralUsage::test_direct_addressing_selects\", \"testing/acceptance_test.py::TestGeneralUsage::test_direct_addressing_notfound\", \"testing/acceptance_test.py::TestGeneralUsage::test_initialization_error_issue49\", \"testing/acceptance_test.py::TestGeneralUsage::test_issue134_report_error_when_collecting_member[test_fun.py::test_a]\", \"testing/acceptance_test.py::TestGeneralUsage::test_report_all_failed_collections_initargs\", \"testing/acceptance_test.py::TestGeneralUsage::test_namespace_import_doesnt_confuse_import_hook\", \"testing/acceptance_test.py::TestGeneralUsage::test_unknown_option\", \"testing/acceptance_test.py::TestGeneralUsage::test_getsourcelines_error_issue553\", \"testing/acceptance_test.py::TestGeneralUsage::test_plugins_given_as_strings\", \"testing/acceptance_test.py::TestGeneralUsage::test_parametrized_with_bytes_regex\", \"testing/acceptance_test.py::TestGeneralUsage::test_parametrized_with_null_bytes\", \"testing/acceptance_test.py::TestInvocationVariants::test_earlyinit\", \"testing/acceptance_test.py::TestInvocationVariants::test_pydoc\", \"testing/acceptance_test.py::TestInvocationVariants::test_import_star_pytest\", \"testing/acceptance_test.py::TestInvocationVariants::test_double_pytestcmdline\", \"testing/acceptance_test.py::TestInvocationVariants::test_python_minus_m_invocation_ok\", \"testing/acceptance_test.py::TestInvocationVariants::test_python_minus_m_invocation_fail\", \"testing/acceptance_test.py::TestInvocationVariants::test_python_pytest_package\", \"testing/acceptance_test.py::TestInvocationVariants::test_invoke_with_path\", \"testing/acceptance_test.py::TestInvocationVariants::test_pyargs_importerror\", \"testing/acceptance_test.py::TestInvocationVariants::test_pyargs_only_imported_once\", \"testing/acceptance_test.py::TestInvocationVariants::test_pyargs_filename_looks_like_module\", \"testing/acceptance_test.py::TestInvocationVariants::test_cmdline_python_package\", \"testing/acceptance_test.py::TestInvocationVariants::test_cmdline_python_namespace_package\", \"testing/acceptance_test.py::TestInvocationVariants::test_invoke_test_and_doctestmodules\", \"testing/acceptance_test.py::TestInvocationVariants::test_cmdline_python_package_symlink\", \"testing/acceptance_test.py::TestInvocationVariants::test_cmdline_python_package_not_exists\", \"testing/acceptance_test.py::TestInvocationVariants::test_doctest_id\", \"testing/acceptance_test.py::TestDurations::test_calls\", \"testing/acceptance_test.py::TestDurations::test_calls_show_2\", \"testing/acceptance_test.py::TestDurations::test_calls_showall\", \"testing/acceptance_test.py::TestDurations::test_calls_showall_verbose\", \"testing/acceptance_test.py::TestDurations::test_with_deselected\", \"testing/acceptance_test.py::TestDurations::test_with_failing_collection\", \"testing/acceptance_test.py::TestDurations::test_with_not\", \"testing/acceptance_test.py::TestDurationsWithFixture::test_setup_function\", \"testing/acceptance_test.py::test_zipimport_hook\", \"testing/acceptance_test.py::test_import_plugin_unicode_name\", \"testing/acceptance_test.py::test_pytest_plugins_as_module\", \"testing/acceptance_test.py::test_deferred_hook_checking\", \"testing/acceptance_test.py::test_fixture_order_respects_scope\", \"testing/acceptance_test.py::test_fixture_mock_integration\", \"testing/acceptance_test.py::test_usage_error_code\", \"testing/acceptance_test.py::test_warn_on_async_function\", \"testing/acceptance_test.py::test_warn_on_async_gen_function\", \"testing/acceptance_test.py::test_no_brokenpipeerror_message\", \"testing/acceptance_test.py::test_function_return_non_none_warning\", \"testing/acceptance_test.py::test_fixture_values_leak\", \"testing/acceptance_test.py::test_frame_leak_on_failing_test\", \"testing/acceptance_test.py::test_pdb_can_be_rewritten\", \"testing/acceptance_test.py::test_tee_stdio_captures_and_live_prints\"]",
        "environment_setup_commit": "10056865d2a4784934ce043908a0e78d0578f677",
        "issue_title": "Module imported twice under import-mode=importlib",
        "test_file": "/home/fdse/wy/RepoCodeEdit/data/raw_repo_lite/pytest/testing/test_unraisableexception.py",
        "searched_functions": [
            "def test_unraisable_in_setup(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_it=\"\"\"\n        import pytest\n\n        class BrokenDel:\n            def __del__(self):\n                raise ValueError(\"del is broken\")\n\n        @pytest.fixture\n        def broken_del():\n            obj = BrokenDel()\n            del obj\n\n        def test_it(broken_del): pass\n        def test_2(): pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n    result.stdout.fnmatch_lines(\n        [\n            \"*= warnings summary =*\",\n            \"test_it.py::test_it\",\n            \"  * PytestUnraisableExceptionWarning: Exception ignored in: <function BrokenDel.__del__ at *>\",\n            \"  \",\n            \"  Traceback (most recent call last):\",\n            \"  ValueError: del is broken\",\n            \"  \",\n            \"    warnings.warn(pytest.PytestUnraisableExceptionWarning(msg))\",\n        ]\n    )",
            "def test_unraisable(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_it=\"\"\"\n        class BrokenDel:\n            def __del__(self):\n                raise ValueError(\"del is broken\")\n\n        def test_it():\n            obj = BrokenDel()\n            del obj\n\n        def test_2(): pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n    result.stdout.fnmatch_lines(\n        [\n            \"*= warnings summary =*\",\n            \"test_it.py::test_it\",\n            \"  * PytestUnraisableExceptionWarning: Exception ignored in: <function BrokenDel.__del__ at *>\",\n            \"  \",\n            \"  Traceback (most recent call last):\",\n            \"  ValueError: del is broken\",\n            \"  \",\n            \"    warnings.warn(pytest.PytestUnraisableExceptionWarning(msg))\",\n        ]\n    )",
            "def test_unraisable_warning_error(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_it=f\"\"\"\n        class BrokenDel:\n            def __del__(self) -> None:\n                raise ValueError(\"del is broken\")\n\n        def test_it() -> None:\n            obj = BrokenDel()\n            del obj\n            {\"import gc; gc.collect()\" * PYPY}\n\n        def test_2(): pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == pytest.ExitCode.TESTS_FAILED\n    assert result.parseoutcomes() == {\"passed\": 1, \"failed\": 1}",
            "def test_unraisable_in_teardown(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_it=\"\"\"\n        import pytest\n\n        class BrokenDel:\n            def __del__(self):\n                raise ValueError(\"del is broken\")\n\n        @pytest.fixture\n        def broken_del():\n            yield\n            obj = BrokenDel()\n            del obj\n\n        def test_it(broken_del): pass\n        def test_2(): pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n    result.stdout.fnmatch_lines(\n        [\n            \"*= warnings summary =*\",\n            \"test_it.py::test_it\",\n            \"  * PytestUnraisableExceptionWarning: Exception ignored in: <function BrokenDel.__del__ at *>\",\n            \"  \",\n            \"  Traceback (most recent call last):\",\n            \"  ValueError: del is broken\",\n            \"  \",\n            \"    warnings.warn(pytest.PytestUnraisableExceptionWarning(msg))\",\n        ]\n    )"
        ],
        "imports_info": [],
        "generated_tests": [
            "import pytest\nimport pmxbot\nfrom pmxbot import core, logging\n\nclass TestLoggerStore:\n    @classmethod\n    def setup_class(cls):\n        path = os.path.dirname(os.path.abspath(__file__))\n        configfile = os.path.join(path, 'testconf.yaml')\n        config = pmxbot.dictlib.ConfigDict.from_yaml(configfile)\n        cls.bot = core.initialize(config)\n\n    def test_logger_store(self):\n        try:\n            logging.Logger.store.message(\"logged\", \"testrunner\", \"some text\")\n        except AttributeError as e:\n            pytest.fail(f\"Unexpected error: {e}\")",
            "import os\nimport pmxbot\nfrom pmxbot import core, logging\n\nclass TestLoggerStoreAttribute:\n    def setup_method(self):\n        path = os.path.dirname(os.path.abspath(__file__))\n        configfile = os.path.join(path, 'testconf.yaml')\n        config = pmxbot.dictlib.ConfigDict.from_yaml(configfile)\n        self.bot = core.initialize(config)\n\n    def test_logger_store_attribute(self):\n        assert hasattr(logging.Logger, 'store'), \"Logger class does not have 'store' attribute\"",
            "import os\nimport sys\nimport pmxbot\nfrom pmxbot import core, logging\n\nclass TestLoggerStore:\n    def setup_method(self):\n        path = os.path.dirname(os.path.abspath(__file__))\n        configfile = os.path.join(path, 'testconf.yaml')\n        config = pmxbot.dictlib.ConfigDict.from_yaml(configfile)\n        self.bot = core.initialize(config)\n\n    def test_logger_store(self):\n        assert hasattr(logging.Logger, 'store'), \"Logger class does not have 'store' attribute\"\n\n    def test_single_logging_module(self):\n        assert sys.modules['pmxbot.logging'] is logging, \"Multiple versions of 'pmxbot.logging' present\"",
            "import pytest\nimport pmxbot\nfrom pmxbot import core, logging\n\nclass TestLogging:\n    def setup_method(self):\n        path = os.path.dirname(os.path.abspath(__file__))\n        configfile = os.path.join(path, 'testconf.yaml')\n        self.bot = core.initialize(config)\n\n    def test_logger_store(self):\n        try:\n            logging.Logger.store.message(\"logged\", \"testrunner\", \"some text\")\n        except AttributeError as e:\n            pytest.fail(f\"Unexpected AttributeError: {e}\")",
            "import sys\nimport pytest\nimport pmxbot.logging\nfrom pmxbot import core\n\nclass TestLoggerImport:\n    def setup_class(cls):\n        path = os.path.dirname(os.path.abspath(__file__))\n        configfile = os.path.join(path, 'testconf.yaml')\n        config = pmxbot.dictlib.ConfigDict.from_yaml(configfile)\n        cls.bot = core.initialize(config)\n\n    def test_logger_import(self):\n        # Check if 'pmxbot.logging' is in sys.modules\n        assert 'pmxbot.logging' in sys.modules\n\n        # Get the Logger class from sys.modules\n        logger_sys = sys.modules['pmxbot.logging'].Logger\n\n        # Get the Logger class from pmxbot.logging module\n        logger_pmx = pmxbot.logging.Logger\n\n        # Check if both Logger classes are the same\n        assert logger_sys is logger_pmx\n\n        # Check if 'store' attribute is present in both Logger classes\n        assert hasattr(logger_sys, 'store')\n        assert hasattr(logger_pmx, 'store')"
        ]
    },
    {
        "repo": "pytest-dev/pytest",
        "instance_id": "pytest-dev__pytest-11143",
        "base_commit": "6995257cf470d2143ad1683824962de4071c0eb7",
        "patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -676,6 +676,7 @@ def run(self, mod: ast.Module) -> None:\n                 expect_docstring\n                 and isinstance(item, ast.Expr)\n                 and isinstance(item.value, ast.Constant)\n+                and isinstance(item.value.value, str)\n             ):\n                 doc = item.value.value\n                 if self.is_rewrite_disabled(doc):\n",
        "test_patch": "diff --git a/testing/test_assertrewrite.py b/testing/test_assertrewrite.py\n--- a/testing/test_assertrewrite.py\n+++ b/testing/test_assertrewrite.py\n@@ -2042,3 +2042,17 @@ def test_max_increased_verbosity(self, pytester: Pytester) -> None:\n         self.create_test_file(pytester, DEFAULT_REPR_MAX_SIZE * 10)\n         result = pytester.runpytest(\"-vv\")\n         result.stdout.no_fnmatch_line(\"*xxx...xxx*\")\n+\n+\n+class TestIssue11140:\n+    def test_constant_not_picked_as_module_docstring(self, pytester: Pytester) -> None:\n+        pytester.makepyfile(\n+            \"\"\"\\\n+            0\n+\n+            def test_foo():\n+                pass\n+            \"\"\"\n+        )\n+        result = pytester.runpytest()\n+        assert result.ret == 0\n",
        "problem_statement": "Rewrite fails when first expression of file is a number and mistaken as docstring \n<!--\r\nThanks for submitting an issue!\r\n\r\nQuick check-list while reporting bugs:\r\n-->\r\n\r\n- [x] a detailed description of the bug or problem you are having\r\n- [x] output of `pip list` from the virtual environment you are using\r\n- [x] pytest and operating system versions\r\n- [x] minimal example if possible\r\n```\r\nInstalling collected packages: zipp, six, PyYAML, python-dateutil, MarkupSafe, importlib-metadata, watchdog, tomli, soupsieve, pyyaml-env-tag, pycparser, pluggy, packaging, mergedeep, Markdown, jinja2, iniconfig, ghp-import, exceptiongroup, click, websockets, urllib3, tqdm, smmap, pytest, pyee, mkdocs, lxml, importlib-resources, idna, cssselect, charset-normalizer, cffi, certifi, beautifulsoup4, attrs, appdirs, w3lib, typing-extensions, texttable, requests, pyzstd, pytest-metadata, pyquery, pyppmd, pyppeteer, pynacl, pymdown-extensions, pycryptodomex, pybcj, pyasn1, py, psutil, parse, multivolumefile, mkdocs-autorefs, inflate64, gitdb, fake-useragent, cryptography, comtypes, bs4, brotli, bcrypt, allure-python-commons, xlwt, xlrd, rsa, requests-html, pywinauto, python-i18n, python-dotenv, pytest-rerunfailures, pytest-html, pytest-check, PySocks, py7zr, paramiko, mkdocstrings, loguru, GitPython, ftputil, crcmod, chardet, brotlicffi, allure-pytest\r\nSuccessfully installed GitPython-3.1.31 Markdown-3.3.7 MarkupSafe-2.1.3 PySocks-1.7.1 PyYAML-6.0 allure-pytest-2.13.2 allure-python-commons-2.13.2 appdirs-1.4.4 attrs-23.1.0 bcrypt-4.0.1 beautifulsoup4-4.12.2 brotli-1.0.9 brotlicffi-1.0.9.2 bs4-0.0.1 certifi-2023.5.7 cffi-1.15.1 chardet-5.1.0 charset-normalizer-3.1.0 click-8.1.3 comtypes-1.2.0 crcmod-1.7 cryptography-41.0.1 cssselect-1.2.0 exceptiongroup-1.1.1 fake-useragent-1.1.3 ftputil-5.0.4 ghp-import-2.1.0 gitdb-4.0.10 idna-3.4 importlib-metadata-6.7.0 importlib-resources-5.12.0 inflate64-0.3.1 iniconfig-2.0.0 jinja2-3.1.2 loguru-0.7.0 lxml-4.9.2 mergedeep-1.3.4 mkdocs-1.4.3 mkdocs-autorefs-0.4.1 mkdocstrings-0.22.0 multivolumefile-0.2.3 packaging-23.1 paramiko-3.2.0 parse-1.19.1 pluggy-1.2.0 psutil-5.9.5 py-1.11.0 py7zr-0.20.5 pyasn1-0.5.0 pybcj-1.0.1 pycparser-2.21 pycryptodomex-3.18.0 pyee-8.2.2 pymdown-extensions-10.0.1 pynacl-1.5.0 pyppeteer-1.0.2 pyppmd-1.0.0 pyquery-2.0.0 pytest-7.4.0 pytest-check-2.1.5 pytest-html-3.2.0 pytest-metadata-3.0.0 pytest-rerunfailures-11.1.2 python-dateutil-2.8.2 python-dotenv-1.0.0 python-i18n-0.3.9 pywinauto-0.6.6 pyyaml-env-tag-0.1 pyzstd-0.15.9 requests-2.31.0 requests-html-0.10.0 rsa-4.9 six-1.16.0 smmap-5.0.0 soupsieve-2.4.1 texttable-1.6.7 tomli-2.0.1 tqdm-4.65.0 typing-extensions-4.6.3 urllib3-1.26.16 w3lib-2.1.1 watchdog-3.0.0 websockets-10.4 xlrd-2.0.1 xlwt-1.3.0 zipp-3.15.0\r\n```\r\nuse `pytest -k xxx`\uff0c report an error\uff1a`TypeError: argument of type 'int' is not iterable`\r\n\r\nit seems a error in collecting testcase\r\n```\r\n==================================== ERRORS ====================================\r\n_ ERROR collecting testcases/\u57fa\u7ebf/\u4ee3\u7406\u7b56\u7565/SOCKS\u4e8c\u7ea7\u4ee3\u7406\u8fed\u4ee3\u4e8c/\u5728\u7ebf\u7528\u6237/\u5728\u7ebf\u7528\u6237\u66f4\u65b0/\u4e0a\u7ebf\u7528\u6237/test_socks_user_011.py _\r\n/usr/local/lib/python3.8/site-packages/_pytest/runner.py:341: in from_call\r\n    result: Optional[TResult] = func()\r\n/usr/local/lib/python3.8/site-packages/_pytest/runner.py:372: in <lambda>\r\n    call = CallInfo.from_call(lambda: list(collector.collect()), \"collect\")\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:531: in collect\r\n    self._inject_setup_module_fixture()\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:545: in _inject_setup_module_fixture\r\n    self.obj, (\"setUpModule\", \"setup_module\")\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:310: in obj\r\n    self._obj = obj = self._getobj()\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:528: in _getobj\r\n    return self._importtestmodule()\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:617: in _importtestmodule\r\n    mod = import_path(self.path, mode=importmode, root=self.config.rootpath)\r\n/usr/local/lib/python3.8/site-packages/_pytest/pathlib.py:565: in import_path\r\n    importlib.import_module(module_name)\r\n/usr/local/lib/python3.8/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n<frozen importlib._bootstrap>:1014: in _gcd_import\r\n    ???\r\n<frozen importlib._bootstrap>:991: in _find_and_load\r\n    ???\r\n<frozen importlib._bootstrap>:975: in _find_and_load_unlocked\r\n    ???\r\n<frozen importlib._bootstrap>:671: in _load_unlocked\r\n    ???\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:169: in exec_module\r\n    source_stat, co = _rewrite_test(fn, self.config)\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:352: in _rewrite_test\r\n    rewrite_asserts(tree, source, strfn, config)\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:413: in rewrite_asserts\r\n    AssertionRewriter(module_path, config, source).run(mod)\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:695: in run\r\n    if self.is_rewrite_disabled(doc):\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:760: in is_rewrite_disabled\r\n    return \"PYTEST_DONT_REWRITE\" in docstring\r\nE   TypeError: argument of type 'int' is not iterable\r\n```\n",
        "hints_text": "more details are needed - based on the exception, the docstring is a integer, that seems completely wrong\nI run it pass lasttime in 2023-6-20 17:07:23. it run in docker and install newest pytest before run testcase everytime . maybe some commit cause it recently. \r\nI run it can pass in 7.2.0 a few minutes ago.\r\n\r\n`pytest ini`\r\n```\r\n[pytest]\r\nlog_cli = false\r\nlog_cli_level = debug\r\nlog_cli_format = %(asctime)s %(levelname)s %(message)s\r\nlog_cli_date_format = %Y-%m-%d %H:%M:%S\r\n\r\naddopts = -v -s\r\n\r\nfilterwarnings =\r\n    ignore::UserWarning\r\n\r\nmarkers=\r\n    case_id: mark test id to upload on tp\r\n    case_level_bvt: testcase level bvt\r\n    case_level_1: testcase level level 1\r\n    case_level_2: testcase level level 2\r\n    case_level_3: testcase level level 3\r\n    case_status_pass: mark case as PASS\r\n    case_status_fail: mark case as FAILED\r\n    case_status_not_finish: mark case as CODEING\r\n    case_status_not_run: mark case as FINISH\r\n    case_not_run: mark case as DONT RUN\r\n    run_env: mark run this case on which environment\r\n ```\r\n    \r\n`testcase:`\r\n```\r\n@pytest.fixture(autouse=True)\r\ndef default_setup_teardown():\r\n    xxxx\r\n\r\n@allure.feature(\"\u521d\u59cb\u72b6\u6001\")\r\nclass TestDefauleName:\r\n    @allure.title(\"\u4e0a\u7ebf\u4e00\u4e2a\u57df\u7528\u6237\uff0c\u7528\u6237\u540d\u548c\u7ec4\u540d\u6b63\u786e\")\r\n    @pytest.mark.case_level_1\r\n    @pytest.mark.case_id(\"tc_proxyheard_insert_011\")\r\n    def test_tc_proxyheard_insert_011(self):\r\n        xxxx\r\n        ```\nthanks for the update\r\n\r\ni took the liberty to edit your comments to use markdown code blocks for ease of reading\r\n\r\nfrom the given information the problem is still unclear\r\n\r\nplease try running with `--assert=plain` for verification\r\n\r\nthe error indicates that the python ast parser somehow ends up with a integer as the docstring for `test_socks_user_011.py` the reason is still unclear based on the redacted information\nI run with --assert=plain and it has passed\r\n\r\npython3 -m pytest -k helloworld --assert=plain\r\n```\r\ntestcases/smoke_testcase/test_helloworld.py::TestGuardProcess::test_hello_world 2023-06-25 08:54:17.659 | INFO     | NAC_AIO.testcases.smoke_testcase.test_helloworld:test_hello_world:15 - Great! Frame Work is working\r\nPASSED\r\ntotal: 1648\r\npassed: 1\r\nfailed: 0\r\nerror: 0\r\npass_rate 100.00%\r\n\r\n================================================================================= 1 passed, 1647 deselected in 12.28s =================================================================================\r\n```\nIt seems to me that we have a potential bug in the ast transformer where's in case the first expression of a file is a integer, we mistake it as a docstring\n\nCan you verify the first expression in the file that fails?\nyou are right this file first expression is a 0 . It can pass after I delete it \r\nthank you!\nMinimal reproducer:\r\n\r\n```python\r\n0\r\n```\r\n\r\n(yes, just that, in a .py file)",
        "created_at": "2023-06-26T06:44:43Z",
        "version": "8.0",
        "FAIL_TO_PASS": "[\"testing/test_assertrewrite.py::TestIssue11140::test_constant_not_picked_as_module_docstring\"]",
        "PASS_TO_PASS": "[\"testing/test_assertrewrite.py::TestAssertionRewrite::test_place_initial_imports\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_location_is_set\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_dont_rewrite\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_name\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assertrepr_compare_same_width\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_dont_rewrite_if_hasattr_fails\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assert_already_has_message\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_boolop\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_short_circuit_evaluation\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_unary_op\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_binary_op\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_boolop_percent\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_call\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_attribute\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_comparisons\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_len\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_custom_reprcompare\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assert_raising__bool__in_comparison\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_formatchar\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_custom_repr\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_custom_repr_non_ascii\", \"testing/test_assertrewrite.py::TestAssertionRewriteHookDetails::test_read_pyc\", \"testing/test_assertrewrite.py::TestAssertionRewriteHookDetails::test_read_pyc_more_invalid\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[trivial]\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[assert\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[multiple\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[latin1\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[utf-8\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[multi-line\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[multi\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[backslash\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[assertion\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[escaped\", \"testing/test_assertrewrite.py::test_get_assertion_exprs[no\", \"testing/test_assertrewrite.py::test_try_makedirs\", \"testing/test_assertrewrite.py::TestPyCacheDir::test_get_cache_dir[c:/tmp/pycs-d:/projects/src/foo.py-c:/tmp/pycs/projects/src]\", \"testing/test_assertrewrite.py::TestPyCacheDir::test_get_cache_dir[None-d:/projects/src/foo.py-d:/projects/src/__pycache__]\", \"testing/test_assertrewrite.py::TestPyCacheDir::test_get_cache_dir[/tmp/pycs-/home/projects/src/foo.py-/tmp/pycs/home/projects/src]\", \"testing/test_assertrewrite.py::TestPyCacheDir::test_get_cache_dir[None-/home/projects/src/foo.py-/home/projects/src/__pycache__]\", \"testing/test_assertrewrite.py::TestReprSizeVerbosity::test_get_maxsize_for_saferepr[0-240]\", \"testing/test_assertrewrite.py::TestReprSizeVerbosity::test_get_maxsize_for_saferepr[1-2400]\", \"testing/test_assertrewrite.py::TestReprSizeVerbosity::test_get_maxsize_for_saferepr[2-None]\", \"testing/test_assertrewrite.py::TestReprSizeVerbosity::test_get_maxsize_for_saferepr[3-None]\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_rewrites_plugin_as_a_package\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_honors_pep_235\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assertion_message\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assertion_message_multiline\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assertion_message_tuple\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assertion_message_expr\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assertion_message_escape\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_assertion_messages_bytes\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_at_operator_issue1290\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_starred_with_side_effect\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_pycache_is_a_file\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_pycache_is_readonly\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_zipfile\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_load_resource_via_files_with_rewrite\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_readonly\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_orphaned_pyc_file\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_package\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_translate_newlines\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_package_without__init__py\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_remember_rewritten_modules\", \"testing/test_assertrewrite.py::TestAssertionRewriteHookDetails::test_sys_meta_path_munged\", \"testing/test_assertrewrite.py::TestAssertionRewriteHookDetails::test_write_pyc\", \"testing/test_assertrewrite.py::TestAssertionRewriteHookDetails::test_read_pyc_success\", \"testing/test_assertrewrite.py::TestAssertionRewriteHookDetails::test_reload_is_same_and_reloads\", \"testing/test_assertrewrite.py::TestAssertionRewriteHookDetails::test_get_data_support\", \"testing/test_assertrewrite.py::test_issue731\", \"testing/test_assertrewrite.py::TestIssue925::test_simple_case\", \"testing/test_assertrewrite.py::TestIssue925::test_long_case\", \"testing/test_assertrewrite.py::TestIssue925::test_many_brackets\", \"testing/test_assertrewrite.py::TestIssue2121::test_rewrite_python_files_contain_subdirs\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_operator\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_operator_dont_rewrite\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_inline_walrus_operator\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_inline_walrus_operator_reverse\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_no_variable_name_conflict\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_operator_true_assertion_and_changes_variable_value\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_operator_fail_assertion\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_operator_boolean_composite\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_operator_compare_boolean_fails\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_operator_boolean_none_fails\", \"testing/test_assertrewrite.py::TestIssue10743::test_assertion_walrus_operator_value_changes_cleared_after_each_test\", \"testing/test_assertrewrite.py::TestIssue11028::test_assertion_walrus_operator_in_operand\", \"testing/test_assertrewrite.py::TestIssue11028::test_assertion_walrus_operator_in_operand_json_dumps\", \"testing/test_assertrewrite.py::TestIssue11028::test_assertion_walrus_operator_equals_operand_function\", \"testing/test_assertrewrite.py::TestIssue11028::test_assertion_walrus_operator_equals_operand_function_keyword_arg\", \"testing/test_assertrewrite.py::TestIssue11028::test_assertion_walrus_operator_equals_operand_function_arg_as_function\", \"testing/test_assertrewrite.py::TestIssue11028::test_assertion_walrus_operator_gt_operand_function\", \"testing/test_assertrewrite.py::test_source_mtime_long_long[-1]\", \"testing/test_assertrewrite.py::test_source_mtime_long_long[1]\", \"testing/test_assertrewrite.py::test_rewrite_infinite_recursion\", \"testing/test_assertrewrite.py::TestEarlyRewriteBailout::test_basic\", \"testing/test_assertrewrite.py::TestEarlyRewriteBailout::test_pattern_contains_subdirectories\", \"testing/test_assertrewrite.py::TestEarlyRewriteBailout::test_cwd_changed\", \"testing/test_assertrewrite.py::TestAssertionPass::test_option_default\", \"testing/test_assertrewrite.py::TestAssertionPass::test_hook_call\", \"testing/test_assertrewrite.py::TestAssertionPass::test_hook_call_with_parens\", \"testing/test_assertrewrite.py::TestAssertionPass::test_hook_not_called_without_hookimpl\", \"testing/test_assertrewrite.py::TestAssertionPass::test_hook_not_called_without_cmd_option\", \"testing/test_assertrewrite.py::TestPyCacheDir::test_sys_pycache_prefix_integration\", \"testing/test_assertrewrite.py::TestReprSizeVerbosity::test_default_verbosity\", \"testing/test_assertrewrite.py::TestReprSizeVerbosity::test_increased_verbosity\", \"testing/test_assertrewrite.py::TestReprSizeVerbosity::test_max_increased_verbosity\", \"testing/test_assertrewrite.py::TestAssertionRewrite::test_dont_rewrite_plugin\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_dont_write_bytecode\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_cached_pyc_includes_pytest_version\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_pyc_vs_pyo\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_rewrite_warning\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_rewrite_module_imported_from_conftest\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_rewrite_warning_using_pytest_plugins\", \"testing/test_assertrewrite.py::TestRewriteOnImport::test_rewrite_warning_using_pytest_plugins_env_var\", \"testing/test_assertrewrite.py::TestAssertionRewriteHookDetails::test_resources_provider_for_loader\"]",
        "environment_setup_commit": "10056865d2a4784934ce043908a0e78d0578f677",
        "issue_title": "Rewrite fails when first expression of file is a number and mistaken as docstring ",
        "test_file": "/home/fdse/wy/RepoCodeEdit/data/raw_repo_lite/pytest/testing/test_assertrewrite.py",
        "searched_functions": [
            "def test_dont_rewrite(self) -> None:\n        s = \"\"\"'PYTEST_DONT_REWRITE'\\nassert 14\"\"\"\n        m = rewrite(s)\n        assert len(m.body) == 2\n        assert isinstance(m.body[1], ast.Assert)\n        assert m.body[1].msg is None",
            "def test_assertion_walrus_operator_dont_rewrite(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            'PYTEST_DONT_REWRITE'\n            def my_func(before, after):\n                return before == after\n\n            def change_value(value):\n                return value.lower()\n\n            def test_walrus_conversion_dont_rewrite():\n                a = \"Hello\"\n                assert not my_func(a, a := change_value(a))\n                assert a == \"hello\"\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0",
            "def test_rewrite_python_files_contain_subdirs(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            **{\n                \"tests/file.py\": \"\"\"\n                def test_simple_failure():\n                    assert 1 + 1 == 3\n                \"\"\"\n            }\n        )\n        pytester.makeini(\n            \"\"\"\n                [pytest]\n                python_files = tests/**.py\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*E*assert (1 + 1) == 3\"])",
            "def test_place_initial_imports(self) -> None:\n        s = \"\"\"'Doc string'\\nother = stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Assign)\n        s = \"\"\"from __future__ import division\\nother_stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.ImportFrom)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Expr)\n        s = \"\"\"'doc string'\\nfrom __future__ import division\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        assert isinstance(m.body[1], ast.ImportFrom)\n        for imp in m.body[2:4]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        s = \"\"\"'doc string'\\nfrom __future__ import division\\nother\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        assert isinstance(m.body[1], ast.ImportFrom)\n        for imp in m.body[2:4]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 3\n            assert imp.col_offset == 0\n        assert isinstance(m.body[4], ast.Expr)\n        s = \"\"\"from . import relative\\nother_stuff\"\"\"\n        m = rewrite(s)\n        for imp in m.body[:2]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 1\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Expr)",
            "def test_rewrite_warning_using_pytest_plugins(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            **{\n                \"conftest.py\": \"pytest_plugins = ['core', 'gui', 'sci']\",\n                \"core.py\": \"\",\n                \"gui.py\": \"pytest_plugins = ['core', 'sci']\",\n                \"sci.py\": \"pytest_plugins = ['core']\",\n                \"test_rewrite_warning_pytest_plugins.py\": \"def test(): pass\",\n            }\n        )\n        pytester.chdir()\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*= 1 passed in *=*\"])\n        result.stdout.no_fnmatch_line(\"*pytest-warning summary*\")",
            "def test_rewrite_warning_using_pytest_plugins_env_var(\n        self, pytester: Pytester, monkeypatch\n    ) -> None:\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"plugin\")\n        pytester.makepyfile(\n            **{\n                \"plugin.py\": \"\",\n                \"test_rewrite_warning_using_pytest_plugins_env_var.py\": \"\"\"\n                import plugin\n                pytest_plugins = ['plugin']\n                def test():\n                    pass\n            \"\"\",\n            }\n        )\n        pytester.chdir()\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*= 1 passed in *=*\"])\n        result.stdout.no_fnmatch_line(\"*pytest-warning summary*\")",
            "def test_dont_rewrite_plugin(self, pytester: Pytester) -> None:\n        contents = {\n            \"conftest.py\": \"pytest_plugins = 'plugin'; import plugin\",\n            \"plugin.py\": \"'PYTEST_DONT_REWRITE'\",\n            \"test_foo.py\": \"def test_foo(): pass\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess()\n        assert \"warning\" not in \"\".join(result.outlines)",
            "def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0",
            "def test_rewrite_warning(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*: _pytest\"])",
            "def getmsg(\n    f, extra_ns: Optional[Mapping[str, object]] = None, *, must_pass: bool = False\n) -> Optional[str]:\n    \"\"\"Rewrite the assertions in f, run it, and get the failure message.\"\"\"\n    src = \"\\n\".join(_pytest._code.Code.from_function(f).source().lines)\n    mod = rewrite(src)\n    code = compile(mod, \"<test>\", \"exec\")\n    ns: Dict[str, object] = {}\n    if extra_ns is not None:\n        ns.update(extra_ns)\n    exec(code, ns)\n    func = ns[f.__name__]\n    try:\n        func()  # type: ignore[operator]\n    except AssertionError:\n        if must_pass:\n            pytest.fail(\"shouldn't have raised\")\n        s = str(sys.exc_info()[1])\n        if not s.startswith(\"assert\"):\n            return \"AssertionError: \" + s\n        return s\n    else:\n        if not must_pass:\n            pytest.fail(\"function didn't raise at all\")\n        return None"
        ],
        "imports_info": [],
        "generated_tests": [
            "import pytest\nfrom _pytest.pathlib import import_path\n\nclass TestPytest:\n    def test_number_as_first_expression(self, tmp_path):\n        # Create a python file with a number as the first expression\n        test_file = tmp_path / \"test_file.py\"\n        test_file.write_text(\"1\\n\")\n\n        # Try to import the test file\n        try:\n            import_path(test_file)\n        except TypeError as e:\n            # If a TypeError is raised, the bug is present\n            assert False, f\"Bug is present: {e}\"",
            "import pytest\nimport ast\n\nclass TestFirstExpression:\n    def test_first_expression_number(self):\n        # Create a python file with a number as the first expression\n        with open(\"test_file.py\", \"w\") as file:\n            file.write(\"1\\n\")\n            file.write(\"def test_func():\\n\")\n            file.write(\"    assert 1 == 1\\n\")\n\n        # Run pytest on the created file\n        try:\n            pytest.main([\"test_file.py\"])\n        except TypeError as e:\n            # If a TypeError is raised, the issue is not fixed\n            assert False, f\"TypeError: {e}\"\n        finally:\n            # Delete the test file\n            os.remove(\"test_file.py\")",
            "import pytest\nfrom _pytest.python import Module\nfrom _pytest.config import Config\nfrom _pytest.assertion import rewrite\n\nclass TestFirstExpressionNumber:\n    def test_first_expression_number(self):\n        # Create a python file with a number as the first expression\n        source = \"1\\nassert True\"\n        # Create a dummy config\n        config = Config.fromdictargs({}, [])\n        # Create a dummy module\n        module = Module(config=config, session=None, nodeid=\"dummy\", fspath=None)\n        # Rewrite the module\n        rewrite._rewrite_test(module, config)\n        # Check if the module was rewritten successfully\n        assert module.body[0].value.n == 1\n        assert isinstance(module.body[1], ast.Assert)\n        assert module.body[1].msg is None",
            "import pytest\nfrom _pytest.pathlib import import_path\n\ndef test_number_as_first_expression(tmp_path):\n    # Create a temporary python file with a number as the first expression\n    test_file = tmp_path / \"test_file.py\"\n    test_file.write_text(\"1\\n def test_func(): pass\")\n\n    # Try to import the module\n    try:\n        import_path(test_file)\n    except TypeError as e:\n        pytest.fail(f\"TypeError raised when trying to import module: {e}\")",
            "import pytest\nimport os\nfrom _pytest.pathlib import import_path\n\ndef test_number_as_first_expression():\n    # Create a python file with a number as the first expression\n    with open(\"test_file.py\", \"w\") as f:\n        f.write(\"1\\n\")\n        f.write(\"def test_func():\\n\")\n        f.write(\"    assert 1 == 1\\n\")\n\n    # Run pytest on the created file\n    try:\n        import_path(os.path.abspath(\"test_file.py\"))\n    except TypeError as e:\n        # If a TypeError is raised, check if it's the expected error\n        assert str(e) == \"argument of type 'int' is not iterable\"\n    else:\n        # If no error is raised, fail the test\n        pytest.fail(\"TypeError was not raised\")"
        ]
    },
    {
        "repo": "pytest-dev/pytest",
        "instance_id": "pytest-dev__pytest-8906",
        "base_commit": "69356d20cfee9a81972dcbf93d8caf9eabe113e8",
        "patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -608,10 +608,10 @@ def _importtestmodule(self):\n             if e.allow_module_level:\n                 raise\n             raise self.CollectError(\n-                \"Using pytest.skip outside of a test is not allowed. \"\n-                \"To decorate a test function, use the @pytest.mark.skip \"\n-                \"or @pytest.mark.skipif decorators instead, and to skip a \"\n-                \"module use `pytestmark = pytest.mark.{skip,skipif}.\"\n+                \"Using pytest.skip outside of a test will skip the entire module. \"\n+                \"If that's your intention, pass `allow_module_level=True`. \"\n+                \"If you want to skip a specific test or an entire class, \"\n+                \"use the @pytest.mark.skip or @pytest.mark.skipif decorators.\"\n             ) from e\n         self.config.pluginmanager.consider_module(mod)\n         return mod\n",
        "test_patch": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -1341,7 +1341,7 @@ def test_func():\n     )\n     result = pytester.runpytest()\n     result.stdout.fnmatch_lines(\n-        [\"*Using pytest.skip outside of a test is not allowed*\"]\n+        [\"*Using pytest.skip outside of a test will skip the entire module*\"]\n     )\n \n \n",
        "problem_statement": "Improve handling of skip for module level\nThis is potentially about updating docs, updating error messages or introducing a new API.\r\n\r\nConsider the following scenario:\r\n\r\n`pos_only.py` is using Python 3,8 syntax:\r\n```python\r\ndef foo(a, /, b):\r\n    return a + b\r\n```\r\n\r\nIt should not be tested under Python 3.6 and 3.7.\r\nThis is a proper way to skip the test in Python older than 3.8:\r\n```python\r\nfrom pytest import raises, skip\r\nimport sys\r\nif sys.version_info < (3, 8):\r\n    skip(msg=\"Requires Python >= 3.8\", allow_module_level=True)\r\n\r\n# import must be after the module level skip:\r\nfrom pos_only import *\r\n\r\ndef test_foo():\r\n    assert foo(10, 20) == 30\r\n    assert foo(10, b=20) == 30\r\n    with raises(TypeError):\r\n        assert foo(a=10, b=20)\r\n```\r\n\r\nMy actual test involves parameterize and a 3.8 only class, so skipping the test itself is not sufficient because the 3.8 class was used in the parameterization.\r\n\r\nA naive user will try to initially skip the module like:\r\n\r\n```python\r\nif sys.version_info < (3, 8):\r\n    skip(msg=\"Requires Python >= 3.8\")\r\n```\r\nThis issues this error:\r\n\r\n>Using pytest.skip outside of a test is not allowed. To decorate a test function, use the @pytest.mark.skip or @pytest.mark.skipif decorators instead, and to skip a module use `pytestmark = pytest.mark.{skip,skipif}.\r\n\r\nThe proposed solution `pytestmark = pytest.mark.{skip,skipif}`, does not work  in my case: pytest continues to process the file and fail when it hits the 3.8 syntax (when running with an older version of Python).\r\n\r\nThe correct solution, to use skip as a function is actively discouraged by the error message.\r\n\r\nThis area feels a bit unpolished.\r\nA few ideas to improve:\r\n\r\n1. Explain skip with  `allow_module_level` in the error message. this seems in conflict with the spirit of the message.\r\n2. Create an alternative API to skip a module to make things easier: `skip_module(\"reason\")`, which can call `_skip(msg=msg, allow_module_level=True)`.\r\n\r\n\n",
        "hints_text": "SyntaxErrors are thrown before execution, so how would the skip call stop the interpreter from parsing the 'incorrect' syntax?\r\nunless we hook the interpreter that is.\r\nA solution could be to ignore syntax errors based on some parameter\r\nif needed we can extend this to have some functionality to evaluate conditions in which syntax errors should be ignored\r\nplease note what i suggest will not fix other compatibility issues, just syntax errors\r\n\n> SyntaxErrors are thrown before execution, so how would the skip call stop the interpreter from parsing the 'incorrect' syntax?\r\n\r\nThe Python 3.8 code is included by an import. the idea is that the import should not happen if we are skipping the module.\r\n```python\r\nif sys.version_info < (3, 8):\r\n    skip(msg=\"Requires Python >= 3.8\", allow_module_level=True)\r\n\r\n# import must be after the module level skip:\r\nfrom pos_only import *\r\n```\nHi @omry,\r\n\r\nThanks for raising this.\r\n\r\nDefinitely we should improve that message. \r\n\r\n> Explain skip with allow_module_level in the error message. this seems in conflict with the spirit of the message.\r\n\r\nI'm \ud83d\udc4d on this. 2 is also good, but because `allow_module_level` already exists and is part of the public API, I don't think introducing a new API will really help, better to improve the docs of what we already have.\r\n\r\nPerhaps improve the message to something like this:\r\n\r\n```\r\nUsing pytest.skip outside of a test will skip the entire module, if that's your intention pass `allow_module_level=True`. \r\nIf you want to skip a specific test or entire class, use the @pytest.mark.skip or @pytest.mark.skipif decorators.\r\n```\r\n\r\nI think we can drop the `pytestmark` remark from there, it is not skip-specific and passing `allow_module_level` already accomplishes the same.\r\n\nThanks @nicoddemus.\r\n\r\n> Using pytest.skip outside of a test will skip the entire module, if that's your intention pass `allow_module_level=True`. \r\nIf you want to skip a specific test or entire class, use the @pytest.mark.skip or @pytest.mark.skipif decorators.\r\n\r\nThis sounds clearer.\r\nCan you give a bit of context of why the message is there in the first place?\r\nIt sounds like we should be able to automatically detect if this is skipping a test or skipping the entire module (based on the fact that we can issue the warning).\r\n\r\nMaybe this is addressing some past confusion, or we want to push people toward `pytest.mark.skip[if]`, but if we can detect it automatically - we can also deprecate allow_module_level and make `skip()` do the right thing based on the context it's used in.\n> Maybe this is addressing some past confusion\r\n\r\nThat's exactly it, people would use `@pytest.skip` instead of `@pytest.mark.skip` and skip the whole module:\r\n\r\nhttps://github.com/pytest-dev/pytest/issues/2338#issuecomment-290324255\r\n\r\nFor that reason we don't really want to automatically detect things, but want users to explicitly pass that flag which proves they are not doing it by accident.\r\n\r\nOriginal issue: https://github.com/pytest-dev/pytest/issues/607\nHaving looked at the links, I think the alternative API to skip a module is more appealing.\r\nHere is a proposed end state:\r\n\r\n1. pytest.skip_module is introduced, can be used to skip a module.\r\n2. pytest.skip() is only legal inside of a test. If called outside of a test, an error message is issues.\r\nExample:\r\n\r\n> pytest.skip should only be used inside tests. To skip a module use pytest.skip_module. To completely skip a test function or a test class, use the @pytest.mark.skip or @pytest.mark.skipif decorators.\r\n\r\nGetting to this end state would include deprecating allow_module_level first, directing people using pytest.skip(allow_module_level=True) to use pytest.skip_module().\r\n\r\nI am also fine with just changing the message as you initially proposed but I feel this proposal will result in an healthier state.\r\n\n-0.5 from my side - I think this is too minor to warrant another deprecation and change.\nI agree it would be healthier, but -1 from me for the same reasons as @The-Compiler: we already had a deprecation/change period in order to introduce `allow_module_level`, having yet another one is frustrating/confusing to users, in comparison to the small gains.\nHi, I see that this is still open. If available, I'd like to take this up.",
        "created_at": "2021-07-14T08:00:50Z",
        "version": "7.0",
        "FAIL_TO_PASS": "[\"testing/test_skipping.py::test_module_level_skip_error\"]",
        "PASS_TO_PASS": "[\"testing/test_skipping.py::test_importorskip\", \"testing/test_skipping.py::TestEvaluation::test_no_marker\", \"testing/test_skipping.py::TestEvaluation::test_marked_xfail_no_args\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_no_args\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_with_reason\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice2\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_boolean_without_reason\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_invalid_boolean\", \"testing/test_skipping.py::TestEvaluation::test_skipif_class\", \"testing/test_skipping.py::TestEvaluation::test_skipif_markeval_namespace\", \"testing/test_skipping.py::TestEvaluation::test_skipif_markeval_namespace_multiple\", \"testing/test_skipping.py::TestEvaluation::test_skipif_markeval_namespace_ValueError\", \"testing/test_skipping.py::TestXFail::test_xfail_simple[True]\", \"testing/test_skipping.py::TestXFail::test_xfail_simple[False]\", \"testing/test_skipping.py::TestXFail::test_xfail_xpassed\", \"testing/test_skipping.py::TestXFail::test_xfail_using_platform\", \"testing/test_skipping.py::TestXFail::test_xfail_xpassed_strict\", \"testing/test_skipping.py::TestXFail::test_xfail_run_anyway\", \"testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input0-expected0]\", \"testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input1-expected1]\", \"testing/test_skipping.py::TestXFail::test_xfail_evalfalse_but_fails\", \"testing/test_skipping.py::TestXFail::test_xfail_not_report_default\", \"testing/test_skipping.py::TestXFail::test_xfail_not_run_xfail_reporting\", \"testing/test_skipping.py::TestXFail::test_xfail_not_run_no_setup_run\", \"testing/test_skipping.py::TestXFail::test_xfail_xpass\", \"testing/test_skipping.py::TestXFail::test_xfail_imperative\", \"testing/test_skipping.py::TestXFail::test_xfail_imperative_in_setup_function\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_no_run\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_funcarg_setup\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_runtest_failed\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_runtest_passed_strict\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-TypeError-*1\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[(AttributeError,\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-IndexError-*1\", \"testing/test_skipping.py::TestXFail::test_strict_sanity\", \"testing/test_skipping.py::TestXFail::test_strict_xfail[True]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail[False]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_condition[True]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_condition[False]\", \"testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[True]\", \"testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[False]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[true]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[false]\", \"testing/test_skipping.py::TestXFail::test_xfail_markeval_namespace\", \"testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_setup_issue9\", \"testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_teardown_issue9\", \"testing/test_skipping.py::TestSkip::test_skip_class\", \"testing/test_skipping.py::TestSkip::test_skips_on_false_string\", \"testing/test_skipping.py::TestSkip::test_arg_as_reason\", \"testing/test_skipping.py::TestSkip::test_skip_no_reason\", \"testing/test_skipping.py::TestSkip::test_skip_with_reason\", \"testing/test_skipping.py::TestSkip::test_only_skips_marked_test\", \"testing/test_skipping.py::TestSkip::test_strict_and_skip\", \"testing/test_skipping.py::TestSkip::test_wrong_skip_usage\", \"testing/test_skipping.py::TestSkipif::test_skipif_conditional\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting[\\\"hasattr(sys,\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting[True,\", \"testing/test_skipping.py::TestSkipif::test_skipif_using_platform\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[skipif-SKIP-skipped]\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[xfail-XPASS-xpassed]\", \"testing/test_skipping.py::test_skip_not_report_default\", \"testing/test_skipping.py::test_skipif_class\", \"testing/test_skipping.py::test_skipped_reasons_functional\", \"testing/test_skipping.py::test_skipped_folding\", \"testing/test_skipping.py::test_reportchars\", \"testing/test_skipping.py::test_reportchars_error\", \"testing/test_skipping.py::test_reportchars_all\", \"testing/test_skipping.py::test_reportchars_all_error\", \"testing/test_skipping.py::test_errors_in_xfail_skip_expressions\", \"testing/test_skipping.py::test_xfail_skipif_with_globals\", \"testing/test_skipping.py::test_default_markers\", \"testing/test_skipping.py::test_xfail_test_setup_exception\", \"testing/test_skipping.py::test_imperativeskip_on_xfail_test\", \"testing/test_skipping.py::TestBooleanCondition::test_skipif\", \"testing/test_skipping.py::TestBooleanCondition::test_skipif_noreason\", \"testing/test_skipping.py::TestBooleanCondition::test_xfail\", \"testing/test_skipping.py::test_xfail_item\", \"testing/test_skipping.py::test_module_level_skip_with_allow_module_level\", \"testing/test_skipping.py::test_invalid_skip_keyword_parameter\", \"testing/test_skipping.py::test_mark_xfail_item\", \"testing/test_skipping.py::test_summary_list_after_errors\", \"testing/test_skipping.py::test_relpath_rootdir\"]",
        "environment_setup_commit": "e2ee3144ed6e241dea8d96215fcdca18b3892551",
        "issue_title": "Improve handling of skip for module level",
        "test_file": "/home/fdse/wy/RepoCodeEdit/data/raw_repo_lite/pytest/testing/example_scripts/unittest/test_setup_skip_module.py",
        "searched_functions": [
            "def setUpModule():\n    assert 0",
            "def test(self):\n        assert 0"
        ],
        "imports_info": [],
        "generated_tests": [
            "import pytest\nimport sys\n\ndef test_skip_module():\n    if sys.version_info < (3, 8):\n        pytest.skip(msg=\"Requires Python >= 3.8\", allow_module_level=True)\n    else:\n        from pos_only import *\n        def test_foo():\n            assert foo(10, 20) == 30\n            assert foo(10, b=20) == 30\n            with pytest.raises(TypeError):\n                assert foo(a=10, b=20)",
            "import pytest\nimport sys\n\ndef test_skip_module():\n    if sys.version_info < (3, 8):\n        pytest.skip(msg=\"Requires Python >= 3.8\", allow_module_level=True)\n    else:\n        from pos_only import *\n        def test_foo():\n            assert foo(10, 20) == 30\n            assert foo(10, b=20) == 30\n            with pytest.raises(TypeError):\n                assert foo(a=10, b=20)",
            "import pytest\nimport sys\n\nclass TestSkipModule:\n    @pytest.fixture(autouse=True)\n    def skip_by_py_version(self):\n        if sys.version_info < (3, 8):\n            pytest.skip(\"Requires Python >= 3.8\")\n\n    def test_foo(self):\n        from pos_only import *\n        assert foo(10, 20) == 30\n        assert foo(10, b=20) == 30\n        with pytest.raises(TypeError):\n            assert foo(a=10, b=20)",
            "import pytest\nimport sys\n\ndef test_module_skip():\n    if sys.version_info < (3, 8):\n        pytest.skip(msg=\"Requires Python >= 3.8\", allow_module_level=True)\n    else:\n        from pos_only import *\n        assert foo(10, 20) == 30\n        assert foo(10, b=20) == 30\n        with pytest.raises(TypeError):\n            assert foo(a=10, b=20)",
            "import pytest\nimport sys\n\ndef test_skip_module():\n    if sys.version_info < (3, 8):\n        pytest.skip(msg=\"Requires Python >= 3.8\", allow_module_level=True)\n    else:\n        from pos_only import *\n        assert foo(10, 20) == 30\n        assert foo(10, b=20) == 30\n        with pytest.raises(TypeError):\n            assert foo(a=10, b=20)"
        ]
    },
    {
        "repo": "pytest-dev/pytest",
        "instance_id": "pytest-dev__pytest-7373",
        "base_commit": "7b77fc086aab8b3a8ebc890200371884555eea1e",
        "patch": "diff --git a/src/_pytest/mark/evaluate.py b/src/_pytest/mark/evaluate.py\n--- a/src/_pytest/mark/evaluate.py\n+++ b/src/_pytest/mark/evaluate.py\n@@ -10,25 +10,14 @@\n from ..outcomes import fail\n from ..outcomes import TEST_OUTCOME\n from .structures import Mark\n-from _pytest.config import Config\n from _pytest.nodes import Item\n-from _pytest.store import StoreKey\n \n \n-evalcache_key = StoreKey[Dict[str, Any]]()\n+def compiled_eval(expr: str, d: Dict[str, object]) -> Any:\n+    import _pytest._code\n \n-\n-def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n-    default = {}  # type: Dict[str, object]\n-    evalcache = config._store.setdefault(evalcache_key, default)\n-    try:\n-        return evalcache[expr]\n-    except KeyError:\n-        import _pytest._code\n-\n-        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n-        evalcache[expr] = x = eval(exprcode, d)\n-        return x\n+    exprcode = _pytest._code.compile(expr, mode=\"eval\")\n+    return eval(exprcode, d)\n \n \n class MarkEvaluator:\n@@ -98,7 +87,7 @@ def _istrue(self) -> bool:\n                     self.expr = expr\n                     if isinstance(expr, str):\n                         d = self._getglobals()\n-                        result = cached_eval(self.item.config, expr, d)\n+                        result = compiled_eval(expr, d)\n                     else:\n                         if \"reason\" not in mark.kwargs:\n                             # XXX better be checked at collection time\n",
        "test_patch": "diff --git a/testing/test_mark.py b/testing/test_mark.py\n--- a/testing/test_mark.py\n+++ b/testing/test_mark.py\n@@ -706,6 +706,36 @@ def test_1(parameter):\n         reprec = testdir.inline_run()\n         reprec.assertoutcome(skipped=1)\n \n+    def test_reevaluate_dynamic_expr(self, testdir):\n+        \"\"\"#7360\"\"\"\n+        py_file1 = testdir.makepyfile(\n+            test_reevaluate_dynamic_expr1=\"\"\"\n+            import pytest\n+\n+            skip = True\n+\n+            @pytest.mark.skipif(\"skip\")\n+            def test_should_skip():\n+                assert True\n+        \"\"\"\n+        )\n+        py_file2 = testdir.makepyfile(\n+            test_reevaluate_dynamic_expr2=\"\"\"\n+            import pytest\n+\n+            skip = False\n+\n+            @pytest.mark.skipif(\"skip\")\n+            def test_should_not_skip():\n+                assert True\n+        \"\"\"\n+        )\n+\n+        file_name1 = os.path.basename(py_file1.strpath)\n+        file_name2 = os.path.basename(py_file2.strpath)\n+        reprec = testdir.inline_run(file_name1, file_name2)\n+        reprec.assertoutcome(passed=1, skipped=1)\n+\n \n class TestKeywordSelection:\n     def test_select_simple(self, testdir):\n",
        "problem_statement": "Incorrect caching of skipif/xfail string condition evaluation\nVersion: pytest 5.4.3, current master\r\n\r\npytest caches the evaluation of the string in e.g. `@pytest.mark.skipif(\"sys.platform == 'win32'\")`. The caching key is only the string itself (see `cached_eval` in `_pytest/mark/evaluate.py`). However, the evaluation also depends on the item's globals, so the caching can lead to incorrect results. Example:\r\n\r\n```py\r\n# test_module_1.py\r\nimport pytest\r\n\r\nskip = True\r\n\r\n@pytest.mark.skipif(\"skip\")\r\ndef test_should_skip():\r\n    assert False\r\n```\r\n\r\n```py\r\n# test_module_2.py\r\nimport pytest\r\n\r\nskip = False\r\n\r\n@pytest.mark.skipif(\"skip\")\r\ndef test_should_not_skip():\r\n    assert False\r\n```\r\n\r\nRunning `pytest test_module_1.py test_module_2.py`.\r\n\r\nExpected: `test_should_skip` is skipped, `test_should_not_skip` is not skipped.\r\n\r\nActual: both are skipped.\r\n\r\n---\r\n\r\nI think the most appropriate fix is to simply remove the caching, which I don't think is necessary really, and inline `cached_eval` into `MarkEvaluator._istrue`.\n",
        "hints_text": "> I think the most appropriate fix is to simply remove the caching, which I don't think is necessary really, and inline cached_eval into MarkEvaluator._istrue.\r\n\r\nI agree:\r\n\r\n* While it might have some performance impact with very large test suites which use marks with eval, the simple workaround is to not use the eval feature on those, which is more predictable anyway.\r\n* I don't see a clean way to turn \"globals\" in some kind of cache key without having some performance impact and/or adverse effects.\r\n\r\nSo \ud83d\udc4d from me to simply removing this caching. \nAs globals are dynamic, i would propose to drop the cache as well, we should investigate reinstating a cache later on ",
        "created_at": "2020-06-15T17:12:08Z",
        "version": "5.4",
        "FAIL_TO_PASS": "[\"testing/test_mark.py::TestFunctional::test_reevaluate_dynamic_expr\"]",
        "PASS_TO_PASS": "[\"testing/test_mark.py::TestMark::test_pytest_exists_in_namespace_all[py.test-mark]\", \"testing/test_mark.py::TestMark::test_pytest_exists_in_namespace_all[py.test-param]\", \"testing/test_mark.py::TestMark::test_pytest_exists_in_namespace_all[pytest-mark]\", \"testing/test_mark.py::TestMark::test_pytest_exists_in_namespace_all[pytest-param]\", \"testing/test_mark.py::TestMark::test_pytest_mark_notcallable\", \"testing/test_mark.py::TestMark::test_mark_with_param\", \"testing/test_mark.py::TestMark::test_pytest_mark_name_starts_with_underscore\", \"testing/test_mark.py::TestMarkDecorator::test__eq__[lhs0-rhs0-True]\", \"testing/test_mark.py::TestMarkDecorator::test__eq__[lhs1-rhs1-False]\", \"testing/test_mark.py::TestMarkDecorator::test__eq__[lhs2-bar-False]\", \"testing/test_mark.py::TestMarkDecorator::test__eq__[foo-rhs3-False]\", \"testing/test_mark.py::TestMarkDecorator::test_aliases\", \"testing/test_mark.py::test_addmarker_order\", \"testing/test_mark.py::test_pytest_param_id_requires_string\", \"testing/test_mark.py::test_pytest_param_id_allows_none_or_string[None]\", \"testing/test_mark.py::test_pytest_param_id_allows_none_or_string[hello\", \"testing/test_mark.py::test_marked_class_run_twice\", \"testing/test_mark.py::test_ini_markers\", \"testing/test_mark.py::test_markers_option\", \"testing/test_mark.py::test_ini_markers_whitespace\", \"testing/test_mark.py::test_marker_without_description\", \"testing/test_mark.py::test_markers_option_with_plugin_in_current_dir\", \"testing/test_mark.py::test_mark_on_pseudo_function\", \"testing/test_mark.py::test_strict_prohibits_unregistered_markers[--strict-markers]\", \"testing/test_mark.py::test_strict_prohibits_unregistered_markers[--strict]\", \"testing/test_mark.py::test_mark_option[xyz-expected_passed0]\", \"testing/test_mark.py::test_mark_option[(((\", \"testing/test_mark.py::test_mark_option[not\", \"testing/test_mark.py::test_mark_option[xyz\", \"testing/test_mark.py::test_mark_option[xyz2-expected_passed4]\", \"testing/test_mark.py::test_mark_option_custom[interface-expected_passed0]\", \"testing/test_mark.py::test_mark_option_custom[not\", \"testing/test_mark.py::test_keyword_option_custom[interface-expected_passed0]\", \"testing/test_mark.py::test_keyword_option_custom[not\", \"testing/test_mark.py::test_keyword_option_custom[pass-expected_passed2]\", \"testing/test_mark.py::test_keyword_option_custom[1\", \"testing/test_mark.py::test_keyword_option_considers_mark\", \"testing/test_mark.py::test_keyword_option_parametrize[None-expected_passed0]\", \"testing/test_mark.py::test_keyword_option_parametrize[[1.3]-expected_passed1]\", \"testing/test_mark.py::test_keyword_option_parametrize[2-3-expected_passed2]\", \"testing/test_mark.py::test_parametrize_with_module\", \"testing/test_mark.py::test_keyword_option_wrong_arguments[foo\", \"testing/test_mark.py::test_keyword_option_wrong_arguments[(foo-at\", \"testing/test_mark.py::test_keyword_option_wrong_arguments[or\", \"testing/test_mark.py::test_keyword_option_wrong_arguments[not\", \"testing/test_mark.py::test_parametrized_collected_from_command_line\", \"testing/test_mark.py::test_parametrized_collect_with_wrong_args\", \"testing/test_mark.py::test_parametrized_with_kwargs\", \"testing/test_mark.py::test_parametrize_iterator\", \"testing/test_mark.py::TestFunctional::test_merging_markers_deep\", \"testing/test_mark.py::TestFunctional::test_mark_decorator_subclass_does_not_propagate_to_base\", \"testing/test_mark.py::TestFunctional::test_mark_should_not_pass_to_siebling_class\", \"testing/test_mark.py::TestFunctional::test_mark_decorator_baseclasses_merged\", \"testing/test_mark.py::TestFunctional::test_mark_closest\", \"testing/test_mark.py::TestFunctional::test_mark_with_wrong_marker\", \"testing/test_mark.py::TestFunctional::test_mark_dynamically_in_funcarg\", \"testing/test_mark.py::TestFunctional::test_no_marker_match_on_unmarked_names\", \"testing/test_mark.py::TestFunctional::test_keywords_at_node_level\", \"testing/test_mark.py::TestFunctional::test_keyword_added_for_session\", \"testing/test_mark.py::TestFunctional::test_mark_from_parameters\", \"testing/test_mark.py::TestKeywordSelection::test_select_simple\", \"testing/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx]\", \"testing/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx\", \"testing/test_mark.py::TestKeywordSelection::test_select_extra_keywords[TestClass]\", \"testing/test_mark.py::TestKeywordSelection::test_select_extra_keywords[TestClass\", \"testing/test_mark.py::TestKeywordSelection::test_select_starton\", \"testing/test_mark.py::TestKeywordSelection::test_keyword_extra\", \"testing/test_mark.py::TestKeywordSelection::test_no_magic_values[__]\", \"testing/test_mark.py::TestKeywordSelection::test_no_magic_values[+]\", \"testing/test_mark.py::TestKeywordSelection::test_no_magic_values[..]\", \"testing/test_mark.py::TestKeywordSelection::test_no_match_directories_outside_the_suite\", \"testing/test_mark.py::test_parameterset_for_parametrize_marks[None]\", \"testing/test_mark.py::test_parameterset_for_parametrize_marks[]\", \"testing/test_mark.py::test_parameterset_for_parametrize_marks[skip]\", \"testing/test_mark.py::test_parameterset_for_parametrize_marks[xfail]\", \"testing/test_mark.py::test_parameterset_for_fail_at_collect\", \"testing/test_mark.py::test_parameterset_for_parametrize_bad_markname\", \"testing/test_mark.py::test_mark_expressions_no_smear\", \"testing/test_mark.py::test_markers_from_parametrize\", \"testing/test_mark.py::test_marker_expr_eval_failure_handling[NOT\", \"testing/test_mark.py::test_marker_expr_eval_failure_handling[bogus/]\"]",
        "environment_setup_commit": "678c1a0745f1cf175c442c719906a1f13e496910",
        "issue_title": "Incorrect caching of skipif/xfail string condition evaluation",
        "test_file": "/home/fdse/wy/RepoCodeEdit/data/raw_repo_lite/pytest/testing/test_mark_expression.py",
        "searched_functions": [
            "def test_syntax_oddeties(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected",
            "def test_basic(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected",
            "def test_syntax_errors(expr: str, column: int, message: str) -> None:\n    with pytest.raises(ParseError) as excinfo:\n        evaluate(expr, lambda ident: True)\n    assert excinfo.value.column == column\n    assert excinfo.value.message == message",
            "def test_empty_is_false() -> None:\n    assert not evaluate(\"\", lambda ident: False)\n    assert not evaluate(\"\", lambda ident: True)\n    assert not evaluate(\"   \", lambda ident: False)\n    assert not evaluate(\"\\t\", lambda ident: False)",
            "def test_invalid_idents(ident: str) -> None:\n    with pytest.raises(ParseError):\n        evaluate(ident, lambda ident: True)",
            "def evaluate(input: str, matcher: Callable[[str], bool]) -> bool:\n    return Expression.compile(input).evaluate(matcher)",
            "def test_valid_idents(ident: str) -> None:\n    assert evaluate(ident, {ident: True}.__getitem__)"
        ],
        "imports_info": [],
        "generated_tests": [
            "import pytest\n\nclass TestSkipifCaching:\n    def test_skipif_caching(self):\n        # test_module_1.py\n        skip = True\n\n        @pytest.mark.skipif(\"skip\")\n        def test_should_skip():\n            assert False\n\n        # test_module_2.py\n        skip = False\n\n        @pytest.mark.skipif(\"skip\")\n        def test_should_not_skip():\n            assert False\n\n        # Run pytest and collect results\n        result = pytest.main(['test_module_1.py', 'test_module_2.py'])\n\n        # Check if the tests are skipped as expected\n        assert result.tests_collected[0].outcome == 'skipped'\n        assert result.tests_collected[1].outcome == 'failed'",
            "import pytest\n\nclass TestSkipifCaching:\n    def test_skipif_caching(self):\n        # test_module_1.py\n        skip = True\n\n        @pytest.mark.skipif(\"skip\")\n        def test_should_skip():\n            assert False\n\n        # test_module_2.py\n        skip = False\n\n        @pytest.mark.skipif(\"skip\")\n        def test_should_not_skip():\n            assert False\n\n        # Run the tests\n        result = pytest.main(['test_module_1.py', 'test_module_2.py'])\n\n        # Check the results\n        assert result.ret == 0\n        assert result.parseoutcomes()['skipped'] == 1\n        assert result.parseoutcomes()['failed'] == 1",
            "import pytest\n\nclass TestSkipifCaching:\n    def test_module_1(self):\n        skip = True\n\n        @pytest.mark.skipif(\"skip\")\n        def test_should_skip():\n            assert False\n\n        # Run the test and check if it is skipped\n        result = pytest.run(test_should_skip)\n        assert result.wasSuccessful()\n        assert result.testsRun == 1\n        assert len(result.skipped) == 1\n\n    def test_module_2(self):\n        skip = False\n\n        @pytest.mark.skipif(\"skip\")\n        def test_should_not_skip():\n            assert False\n\n        # Run the test and check if it is not skipped\n        result = pytest.run(test_should_not_skip)\n        assert not result.wasSuccessful()\n        assert result.testsRun == 1\n        assert len(result.skipped) == 0",
            "import pytest\n\ndef test_skipif_caching():\n    # test_module_1.py\n    skip = True\n\n    @pytest.mark.skipif(\"skip\")\n    def test_should_skip():\n        assert False\n\n    # Run the test\n    result = pytest.run(test_should_skip)\n    # The test should be skipped\n    assert result.skipped\n\n    # test_module_2.py\n    skip = False\n\n    @pytest.mark.skipif(\"skip\")\n    def test_should_not_skip():\n        assert False\n\n    # Run the test\n    result = pytest.run(test_should_not_skip)\n    # The test should not be skipped\n    assert not result.skipped",
            "import pytest\n\nclass TestSkipIf:\n    def test_module_1(self):\n        skip = True\n\n        @pytest.mark.skipif(\"skip\")\n        def test_should_skip():\n            assert False\n\n        try:\n            test_should_skip()\n        except AssertionError:\n            pytest.fail(\"test_should_skip should have been skipped but it was not\")\n\n    def test_module_2(self):\n        skip = False\n\n        @pytest.mark.skipif(\"skip\")\n        def test_should_not_skip():\n            assert False\n\n        with pytest.raises(AssertionError):\n            test_should_not_skip()"
        ]
    },
    {
        "repo": "pytest-dev/pytest",
        "instance_id": "pytest-dev__pytest-7432",
        "base_commit": "e6e300e729dd33956e5448d8be9a0b1540b4e53a",
        "patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,8 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n",
        "test_patch": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -235,6 +235,31 @@ def test_func2():\n             [\"*def test_func():*\", \"*assert 0*\", \"*1 failed*1 pass*\"]\n         )\n \n+    @pytest.mark.parametrize(\n+        \"test_input,expected\",\n+        [\n+            (\n+                [\"-rs\"],\n+                [\"SKIPPED [1] test_sample.py:2: unconditional skip\", \"*1 skipped*\"],\n+            ),\n+            (\n+                [\"-rs\", \"--runxfail\"],\n+                [\"SKIPPED [1] test_sample.py:2: unconditional skip\", \"*1 skipped*\"],\n+            ),\n+        ],\n+    )\n+    def test_xfail_run_with_skip_mark(self, testdir, test_input, expected):\n+        testdir.makepyfile(\n+            test_sample=\"\"\"\n+            import pytest\n+            @pytest.mark.skip\n+            def test_skip_location() -> None:\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(*test_input)\n+        result.stdout.fnmatch_lines(expected)\n+\n     def test_xfail_evalfalse_but_fails(self, testdir):\n         item = testdir.getitem(\n             \"\"\"\n",
        "problem_statement": "skipping: --runxfail breaks pytest.mark.skip location reporting\npytest versions: 5.4.x, current master\r\n\r\nWhen `@pytest.mark.skip`/`skipif` marks are used to skip a test, for example\r\n\r\n```py\r\nimport pytest\r\n@pytest.mark.skip\r\ndef test_skip_location() -> None:\r\n    assert 0\r\n```\r\n\r\nthe expected skip location reported should point to the item itself, and this is indeed what happens when running with `pytest -rs`:\r\n\r\n```\r\nSKIPPED [1] test_it.py:3: unconditional skip\r\n```\r\n\r\nHowever, adding `pytest -rs --runxfail` breaks this:\r\n\r\n```\r\nSKIPPED [1] src/_pytest/skipping.py:238: unconditional skip\r\n```\r\n\r\nThe `--runxfail` is only about xfail and should not affect this at all.\r\n\r\n---\r\n\r\nHint: the bug is in `src/_pytest/skipping.py`, the `pytest_runtest_makereport` hook.\n",
        "hints_text": "Can I look into this one?\n@debugduck Sure!\nAwesome! I'll get started on it and open up a PR when I find it. I'm a bit new, so I'm still learning about the code base.",
        "created_at": "2020-06-29T21:51:15Z",
        "version": "5.4",
        "FAIL_TO_PASS": "[\"testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input1-expected1]\"]",
        "PASS_TO_PASS": "[\"testing/test_skipping.py::test_importorskip\", \"testing/test_skipping.py::TestEvaluation::test_no_marker\", \"testing/test_skipping.py::TestEvaluation::test_marked_xfail_no_args\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_no_args\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_with_reason\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice2\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_boolean_without_reason\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_invalid_boolean\", \"testing/test_skipping.py::TestEvaluation::test_skipif_class\", \"testing/test_skipping.py::TestXFail::test_xfail_simple[True]\", \"testing/test_skipping.py::TestXFail::test_xfail_simple[False]\", \"testing/test_skipping.py::TestXFail::test_xfail_xpassed\", \"testing/test_skipping.py::TestXFail::test_xfail_using_platform\", \"testing/test_skipping.py::TestXFail::test_xfail_xpassed_strict\", \"testing/test_skipping.py::TestXFail::test_xfail_run_anyway\", \"testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input0-expected0]\", \"testing/test_skipping.py::TestXFail::test_xfail_evalfalse_but_fails\", \"testing/test_skipping.py::TestXFail::test_xfail_not_report_default\", \"testing/test_skipping.py::TestXFail::test_xfail_not_run_xfail_reporting\", \"testing/test_skipping.py::TestXFail::test_xfail_not_run_no_setup_run\", \"testing/test_skipping.py::TestXFail::test_xfail_xpass\", \"testing/test_skipping.py::TestXFail::test_xfail_imperative\", \"testing/test_skipping.py::TestXFail::test_xfail_imperative_in_setup_function\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_no_run\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_funcarg_setup\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-TypeError-*1\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[(AttributeError,\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-IndexError-*1\", \"testing/test_skipping.py::TestXFail::test_strict_sanity\", \"testing/test_skipping.py::TestXFail::test_strict_xfail[True]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail[False]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_condition[True]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_condition[False]\", \"testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[True]\", \"testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[False]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[true]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[false]\", \"testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_setup_issue9\", \"testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_teardown_issue9\", \"testing/test_skipping.py::TestSkip::test_skip_class\", \"testing/test_skipping.py::TestSkip::test_skips_on_false_string\", \"testing/test_skipping.py::TestSkip::test_arg_as_reason\", \"testing/test_skipping.py::TestSkip::test_skip_no_reason\", \"testing/test_skipping.py::TestSkip::test_skip_with_reason\", \"testing/test_skipping.py::TestSkip::test_only_skips_marked_test\", \"testing/test_skipping.py::TestSkip::test_strict_and_skip\", \"testing/test_skipping.py::TestSkipif::test_skipif_conditional\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting[\\\"hasattr(sys,\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting[True,\", \"testing/test_skipping.py::TestSkipif::test_skipif_using_platform\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[skipif-SKIP-skipped]\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[xfail-XPASS-xpassed]\", \"testing/test_skipping.py::test_skip_not_report_default\", \"testing/test_skipping.py::test_skipif_class\", \"testing/test_skipping.py::test_skipped_reasons_functional\", \"testing/test_skipping.py::test_skipped_folding\", \"testing/test_skipping.py::test_reportchars\", \"testing/test_skipping.py::test_reportchars_error\", \"testing/test_skipping.py::test_reportchars_all\", \"testing/test_skipping.py::test_reportchars_all_error\", \"testing/test_skipping.py::test_errors_in_xfail_skip_expressions\", \"testing/test_skipping.py::test_xfail_skipif_with_globals\", \"testing/test_skipping.py::test_default_markers\", \"testing/test_skipping.py::test_xfail_test_setup_exception\", \"testing/test_skipping.py::test_imperativeskip_on_xfail_test\", \"testing/test_skipping.py::TestBooleanCondition::test_skipif\", \"testing/test_skipping.py::TestBooleanCondition::test_skipif_noreason\", \"testing/test_skipping.py::TestBooleanCondition::test_xfail\", \"testing/test_skipping.py::test_xfail_item\", \"testing/test_skipping.py::test_module_level_skip_error\", \"testing/test_skipping.py::test_module_level_skip_with_allow_module_level\", \"testing/test_skipping.py::test_invalid_skip_keyword_parameter\", \"testing/test_skipping.py::test_mark_xfail_item\", \"testing/test_skipping.py::test_summary_list_after_errors\", \"testing/test_skipping.py::test_relpath_rootdir\"]",
        "environment_setup_commit": "678c1a0745f1cf175c442c719906a1f13e496910",
        "issue_title": "skipping: --runxfail breaks pytest.mark.skip location reporting",
        "test_file": "/home/fdse/wy/RepoCodeEdit/data/raw_repo_lite/pytest/testing/test_skipping.py",
        "searched_functions": [
            "def test_skip_no_reason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])",
            "def test_imperativeskip_on_xfail_test(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n        def test_that_fails():\n            assert 0\n\n        @pytest.mark.skipif(\"True\")\n        def test_hello():\n            pass\n    \"\"\"\n    )\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        def pytest_runtest_setup(item):\n            pytest.skip(\"abc\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rsxX\")\n    result.stdout.fnmatch_lines_random(\n        \"\"\"\n        *SKIP*abc*\n        *SKIP*condition: True*\n        *2 skipped*\n    \"\"\"\n    )",
            "def test_xfail_skipif_with_globals(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        x = 3\n        @pytest.mark.skipif(\"x == 3\")\n        def test_skip1():\n            pass\n        @pytest.mark.xfail(\"x == 3\")\n        def test_boolean():\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rsx\")\n    result.stdout.fnmatch_lines([\"*SKIP*x == 3*\", \"*XFAIL*test_boolean*\", \"*x == 3*\"])",
            "def test_skip_not_report_default(testdir):\n    p = testdir.makepyfile(\n        test_one=\"\"\"\n        import pytest\n        def test_this():\n            pytest.skip(\"hello\")\n    \"\"\"\n    )\n    result = testdir.runpytest(p, \"-v\")\n    result.stdout.fnmatch_lines(\n        [\n            # \"*HINT*use*-r*\",\n            \"*1 skipped*\"\n        ]\n    )",
            "def test_strict_and_skip(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])",
            "def test_errors_in_xfail_skip_expressions(testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"asd\")\n        def test_nameerror():\n            pass\n        @pytest.mark.xfail(\"syntax error\")\n        def test_syntax():\n            pass\n\n        def test_func():\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    markline = \"                ^\"\n    pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n    if pypy_version_info is not None and pypy_version_info < (6,):\n        markline = markline[5:]\n    elif sys.version_info >= (3, 8) or hasattr(sys, \"pypy_version_info\"):\n        markline = markline[4:]\n    result.stdout.fnmatch_lines(\n        [\n            \"*ERROR*test_nameerror*\",\n            \"*evaluating*skipif*condition*\",\n            \"*asd*\",\n            \"*ERROR*test_syntax*\",\n            \"*evaluating*xfail*condition*\",\n            \"    syntax error\",\n            markline,\n            \"SyntaxError: invalid syntax\",\n            \"*1 pass*2 errors*\",\n        ]\n    )",
            "def test_only_skips_marked_test(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n            @pytest.mark.skip(reason=\"nothing in particular\")\n            def test_bar():\n                pass\n            def test_baz():\n                assert True\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*nothing in particular*\", \"*1 passed*2 skipped*\"])",
            "def test_skipif_noreason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(True)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *1 error*\n        \"\"\"\n        )",
            "def test_skipped_folding(testdir):\n    testdir.makepyfile(\n        test_one=\"\"\"\n            import pytest\n            pytestmark = pytest.mark.skip(\"Folding\")\n            def setup_function(func):\n                pass\n            def test_func():\n                pass\n            class TestClass(object):\n                def test_method(self):\n                    pass\n       \"\"\"\n    )\n    result = testdir.runpytest(\"-rs\")\n    result.stdout.fnmatch_lines([\"*SKIP*2*test_one.py: Folding\"])\n    assert result.ret == 0",
            "def test_skip_with_reason(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip(reason=\"for lolz\")\n            def test_bar():\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*for lolz*\", \"*1 skipped*\"])"
        ],
        "imports_info": [],
        "generated_tests": [
            "import pytest\n\nclass TestSkipLocation:\n    @pytest.mark.skip\n    def test_skip_location(self):\n        assert 0\n\n    def test_skip_location_report(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_skip_location():\n                assert 0\n            \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\", \"--runxfail\")\n        result.stdout.fnmatch_lines([\"*test_skip_location.py:3: unconditional skip*\"])",
            "import pytest\n\nclass TestSkipLocation:\n    @pytest.mark.skip\n    def test_skip_location(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\", \"--runxfail\")\n        assert \"*unconditional skip*\" in result.stdout.str()\n        assert \"*1 skipped*\" in result.stdout.str()\n        assert \"src/_pytest/skipping.py\" not in result.stdout.str()",
            "import pytest\n\nclass TestSkipLocation:\n    @pytest.mark.skip\n    def test_skip_location(self):\n        \"\"\"\n        Test to check the skip location when using @pytest.mark.skip\n        \"\"\"\n        assert 0\n\n    def test_skip_location_with_runxfail(self, testdir):\n        \"\"\"\n        Test to check the skip location when using @pytest.mark.skip with --runxfail\n        \"\"\"\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_skip_location() -> None:\n                assert 0\n            \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\")\n        result_runxfail = testdir.runpytest(\"-rs\", \"--runxfail\")\n        assert result.outlines[1] == result_runxfail.outlines[1]",
            "import pytest\n\nclass TestSkipLocation:\n    @pytest.mark.skip\n    def test_skip_location(self):\n        assert 0\n\n    def test_run(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_skip_location():\n                assert 0\n            \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\", \"--runxfail\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n        assert \"src/_pytest/skipping.py\" not in result.stdout.str()",
            "import pytest\n\nclass TestSkipLocation:\n    @pytest.mark.skip\n    def test_skip_location(self):\n        assert 0\n\n    def test_skip_location_report(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_skip_location():\n                assert 0\n            \"\"\"\n        )\n        result = testdir.runpytest(\"-rs\", \"--runxfail\")\n        result.stdout.fnmatch_lines([\"*test_skip_location.py:3: unconditional skip*\"])"
        ]
    },
    {
        "repo": "pytest-dev/pytest",
        "instance_id": "pytest-dev__pytest-6116",
        "base_commit": "e670ff76cbad80108bde9bab616b66771b8653cf",
        "patch": "diff --git a/src/_pytest/main.py b/src/_pytest/main.py\n--- a/src/_pytest/main.py\n+++ b/src/_pytest/main.py\n@@ -109,6 +109,7 @@ def pytest_addoption(parser):\n     group.addoption(\n         \"--collectonly\",\n         \"--collect-only\",\n+        \"--co\",\n         action=\"store_true\",\n         help=\"only collect tests, don't execute them.\",\n     ),\n",
        "test_patch": "diff --git a/testing/test_collection.py b/testing/test_collection.py\n--- a/testing/test_collection.py\n+++ b/testing/test_collection.py\n@@ -402,7 +402,7 @@ def pytest_collect_file(path, parent):\n         )\n         testdir.mkdir(\"sub\")\n         testdir.makepyfile(\"def test_x(): pass\")\n-        result = testdir.runpytest(\"--collect-only\")\n+        result = testdir.runpytest(\"--co\")\n         result.stdout.fnmatch_lines([\"*MyModule*\", \"*test_x*\"])\n \n     def test_pytest_collect_file_from_sister_dir(self, testdir):\n@@ -433,7 +433,7 @@ def pytest_collect_file(path, parent):\n         p = testdir.makepyfile(\"def test_x(): pass\")\n         p.copy(sub1.join(p.basename))\n         p.copy(sub2.join(p.basename))\n-        result = testdir.runpytest(\"--collect-only\")\n+        result = testdir.runpytest(\"--co\")\n         result.stdout.fnmatch_lines([\"*MyModule1*\", \"*MyModule2*\", \"*test_x*\"])\n \n \n",
        "problem_statement": "pytest --collect-only needs a one char shortcut command\nI find myself needing to run `--collect-only` very often and that cli argument is a very long to type one. \r\n\r\nI do think that it would be great to allocate a character for it, not sure which one yet. Please use up/down thumbs to vote if you would find it useful or not and eventually proposing which char should be used. \r\n\r\nClearly this is a change very easy to implement but first I want to see if others would find it useful or not.\npytest --collect-only needs a one char shortcut command\nI find myself needing to run `--collect-only` very often and that cli argument is a very long to type one. \r\n\r\nI do think that it would be great to allocate a character for it, not sure which one yet. Please use up/down thumbs to vote if you would find it useful or not and eventually proposing which char should be used. \r\n\r\nClearly this is a change very easy to implement but first I want to see if others would find it useful or not.\n",
        "hints_text": "Agreed, it's probably the option I use most which doesn't have a shortcut.\r\n\r\nBoth `-c` and `-o` are taken. I guess `-n` (as in \"no action\", compare `-n`/`--dry-run` for e.g. `git clean`) could work? \r\n\r\nMaybe `--co` (for either \"**co**llect\" or \"**c**ollect **o**nly), similar to other two-character shortcuts we already have (`--sw`, `--lf`, `--ff`, `--nf`)?\nI like `--co`, and it doesn't seem to be used by any plugins as far as I can search:\r\n\r\nhttps://github.com/search?utf8=%E2%9C%93&q=--co+language%3APython+pytest+language%3APython+language%3APython&type=Code&ref=advsearch&l=Python&l=Python\n> I find myself needing to run `--collect-only` very often and that cli argument is a very long to type one.\r\n\r\nJust out of curiosity: Why?  (i.e. what's your use case?)\r\n\r\n+0 for `--co`.\r\n\r\nBut in general you can easily also have an alias \"alias pco='pytest --collect-only'\" - (or \"alias pco='p --collect-only\" if you have a shortcut for pytest already.. :))\nI routinely use `--collect-only` when I switch to a different development branch or start working on a different area of our code base. I think `--co` is fine.\nAgreed, it's probably the option I use most which doesn't have a shortcut.\r\n\r\nBoth `-c` and `-o` are taken. I guess `-n` (as in \"no action\", compare `-n`/`--dry-run` for e.g. `git clean`) could work? \r\n\r\nMaybe `--co` (for either \"**co**llect\" or \"**c**ollect **o**nly), similar to other two-character shortcuts we already have (`--sw`, `--lf`, `--ff`, `--nf`)?\nI like `--co`, and it doesn't seem to be used by any plugins as far as I can search:\r\n\r\nhttps://github.com/search?utf8=%E2%9C%93&q=--co+language%3APython+pytest+language%3APython+language%3APython&type=Code&ref=advsearch&l=Python&l=Python\n> I find myself needing to run `--collect-only` very often and that cli argument is a very long to type one.\r\n\r\nJust out of curiosity: Why?  (i.e. what's your use case?)\r\n\r\n+0 for `--co`.\r\n\r\nBut in general you can easily also have an alias \"alias pco='pytest --collect-only'\" - (or \"alias pco='p --collect-only\" if you have a shortcut for pytest already.. :))\nI routinely use `--collect-only` when I switch to a different development branch or start working on a different area of our code base. I think `--co` is fine.",
        "created_at": "2019-11-01T20:05:53Z",
        "version": "5.2",
        "FAIL_TO_PASS": "[\"testing/test_collection.py::TestCustomConftests::test_pytest_fs_collect_hooks_are_seen\", \"testing/test_collection.py::TestCustomConftests::test_pytest_collect_file_from_sister_dir\"]",
        "PASS_TO_PASS": "[\"testing/test_collection.py::TestCollector::test_collect_versus_item\", \"testing/test_collection.py::TestCollector::test_check_equality\", \"testing/test_collection.py::TestCollector::test_getparent\", \"testing/test_collection.py::TestCollector::test_getcustomfile_roundtrip\", \"testing/test_collection.py::TestCollector::test_can_skip_class_with_test_attr\", \"testing/test_collection.py::TestCollectFS::test_ignored_certain_directories\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs[activate]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs[activate.csh]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs[activate.fish]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs[Activate]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs[Activate.bat]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs[Activate.ps1]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs_norecursedirs_precedence[activate]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs_norecursedirs_precedence[activate.csh]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs_norecursedirs_precedence[activate.fish]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs_norecursedirs_precedence[Activate]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs_norecursedirs_precedence[Activate.bat]\", \"testing/test_collection.py::TestCollectFS::test_ignored_virtualenvs_norecursedirs_precedence[Activate.ps1]\", \"testing/test_collection.py::TestCollectFS::test__in_venv[activate]\", \"testing/test_collection.py::TestCollectFS::test__in_venv[activate.csh]\", \"testing/test_collection.py::TestCollectFS::test__in_venv[activate.fish]\", \"testing/test_collection.py::TestCollectFS::test__in_venv[Activate]\", \"testing/test_collection.py::TestCollectFS::test__in_venv[Activate.bat]\", \"testing/test_collection.py::TestCollectFS::test__in_venv[Activate.ps1]\", \"testing/test_collection.py::TestCollectFS::test_custom_norecursedirs\", \"testing/test_collection.py::TestCollectFS::test_testpaths_ini\", \"testing/test_collection.py::TestCollectPluginHookRelay::test_pytest_collect_file\", \"testing/test_collection.py::TestCollectPluginHookRelay::test_pytest_collect_directory\", \"testing/test_collection.py::TestPrunetraceback::test_custom_repr_failure\", \"testing/test_collection.py::TestCustomConftests::test_ignore_collect_path\", \"testing/test_collection.py::TestCustomConftests::test_ignore_collect_not_called_on_argument\", \"testing/test_collection.py::TestCustomConftests::test_collectignore_exclude_on_option\", \"testing/test_collection.py::TestCustomConftests::test_collectignoreglob_exclude_on_option\", \"testing/test_collection.py::TestSession::test_parsearg\", \"testing/test_collection.py::TestSession::test_collect_topdir\", \"testing/test_collection.py::TestSession::test_collect_protocol_single_function\", \"testing/test_collection.py::TestSession::test_collect_protocol_method\", \"testing/test_collection.py::TestSession::test_collect_custom_nodes_multi_id\", \"testing/test_collection.py::TestSession::test_collect_subdir_event_ordering\", \"testing/test_collection.py::TestSession::test_collect_two_commandline_args\", \"testing/test_collection.py::TestSession::test_serialization_byid\", \"testing/test_collection.py::TestSession::test_find_byid_without_instance_parents\", \"testing/test_collection.py::Test_getinitialnodes::test_global_file\", \"testing/test_collection.py::Test_getinitialnodes::test_pkgfile\", \"testing/test_collection.py::Test_genitems::test_check_collect_hashes\", \"testing/test_collection.py::Test_genitems::test_example_items1\", \"testing/test_collection.py::Test_genitems::test_class_and_functions_discovery_using_glob\", \"testing/test_collection.py::test_matchnodes_two_collections_same_file\", \"testing/test_collection.py::TestNodekeywords::test_no_under\", \"testing/test_collection.py::TestNodekeywords::test_issue345\", \"testing/test_collection.py::test_exit_on_collection_error\", \"testing/test_collection.py::test_exit_on_collection_with_maxfail_smaller_than_n_errors\", \"testing/test_collection.py::test_exit_on_collection_with_maxfail_bigger_than_n_errors\", \"testing/test_collection.py::test_continue_on_collection_errors\", \"testing/test_collection.py::test_continue_on_collection_errors_maxfail\", \"testing/test_collection.py::test_fixture_scope_sibling_conftests\", \"testing/test_collection.py::test_collect_init_tests\", \"testing/test_collection.py::test_collect_invalid_signature_message\", \"testing/test_collection.py::test_collect_handles_raising_on_dunder_class\", \"testing/test_collection.py::test_collect_with_chdir_during_import\", \"testing/test_collection.py::test_collect_symlink_file_arg\", \"testing/test_collection.py::test_collect_symlink_out_of_tree\", \"testing/test_collection.py::test_collectignore_via_conftest\", \"testing/test_collection.py::test_collect_pkg_init_and_file_in_args\", \"testing/test_collection.py::test_collect_pkg_init_only\", \"testing/test_collection.py::test_collect_sub_with_symlinks[True]\", \"testing/test_collection.py::test_collect_sub_with_symlinks[False]\", \"testing/test_collection.py::test_collector_respects_tbstyle\", \"testing/test_collection.py::test_collect_pyargs_with_testpaths\"]",
        "environment_setup_commit": "f36ea240fe3579f945bf5d6cc41b5e45a572249d",
        "issue_title": "pytest --collect-only needs a one char shortcut command",
        "test_file": "/home/fdse/wy/RepoCodeEdit/data/raw_repo_lite/pytest/testing/test_collection.py",
        "searched_functions": [
            "def test_ignore_collect_path(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            def pytest_ignore_collect(path, config):\n                return path.basename.startswith(\"x\") or \\\n                       path.basename == \"test_one.py\"\n        \"\"\"\n        )\n        sub = testdir.mkdir(\"xy123\")\n        sub.ensure(\"test_hello.py\").write(\"syntax error\")\n        sub.join(\"conftest.py\").write(\"syntax error\")\n        testdir.makepyfile(\"def test_hello(): pass\")\n        testdir.makepyfile(test_one=\"syntax error\")\n        result = testdir.runpytest(\"--fulltrace\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])",
            "def test_collector_respects_tbstyle(testdir):\n    p1 = testdir.makepyfile(\"assert 0\")\n    result = testdir.runpytest(p1, \"--tb=native\")\n    assert result.ret == ExitCode.INTERRUPTED\n    result.stdout.fnmatch_lines(\n        [\n            \"*_ ERROR collecting test_collector_respects_tbstyle.py _*\",\n            \"Traceback (most recent call last):\",\n            '  File \"*/test_collector_respects_tbstyle.py\", line 1, in <module>',\n            \"    assert 0\",\n            \"AssertionError: assert 0\",\n            \"*! Interrupted: 1 error during collection !*\",\n            \"*= 1 error in *\",\n        ]\n    )",
            "def test_collectignoreglob_exclude_on_option(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            collect_ignore_glob = ['*w*l[dt]*']\n            def pytest_addoption(parser):\n                parser.addoption(\"--XX\", action=\"store_true\", default=False)\n            def pytest_configure(config):\n                if config.getvalue(\"XX\"):\n                    collect_ignore_glob[:] = []\n        \"\"\"\n        )\n        testdir.makepyfile(test_world=\"def test_hello(): pass\")\n        testdir.makepyfile(test_welt=\"def test_hallo(): pass\")\n        result = testdir.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines([\"*collected 0 items*\"])\n        result = testdir.runpytest(\"--XX\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*2 passed*\"])",
            "def test_collect_two_commandline_args(self, testdir):\n        p = testdir.makepyfile(\"def test_func(): pass\")\n        aaa = testdir.mkpydir(\"aaa\")\n        bbb = testdir.mkpydir(\"bbb\")\n        test_aaa = aaa.join(\"test_aaa.py\")\n        p.copy(test_aaa)\n        test_bbb = bbb.join(\"test_bbb.py\")\n        p.move(test_bbb)\n\n        id = \".\"\n\n        items, hookrec = testdir.inline_genitems(id)\n        assert len(items) == 2\n        pprint.pprint(hookrec.calls)\n        hookrec.assert_contains(\n            [\n                (\"pytest_collectstart\", \"collector.fspath == test_aaa\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.nodeid == 'aaa/test_aaa.py'\"),\n                (\"pytest_collectstart\", \"collector.fspath == test_bbb\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.nodeid == 'bbb/test_bbb.py'\"),\n            ]\n        )",
            "def test_collectignore_exclude_on_option(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            collect_ignore = ['hello', 'test_world.py']\n            def pytest_addoption(parser):\n                parser.addoption(\"--XX\", action=\"store_true\", default=False)\n            def pytest_configure(config):\n                if config.getvalue(\"XX\"):\n                    collect_ignore[:] = []\n        \"\"\"\n        )\n        testdir.mkdir(\"hello\")\n        testdir.makepyfile(test_world=\"def test_hello(): pass\")\n        result = testdir.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.no_fnmatch_line(\"*passed*\")\n        result = testdir.runpytest(\"--XX\")\n        assert result.ret == 0\n        assert \"passed\" in result.stdout.str()",
            "def test_collect_protocol_single_function(self, testdir):\n        p = testdir.makepyfile(\"def test_func(): pass\")\n        id = \"::\".join([p.basename, \"test_func\"])\n        items, hookrec = testdir.inline_genitems(id)\n        item, = items\n        assert item.name == \"test_func\"\n        newid = item.nodeid\n        assert newid == id\n        pprint.pprint(hookrec.calls)\n        topdir = testdir.tmpdir  # noqa\n        hookrec.assert_contains(\n            [\n                (\"pytest_collectstart\", \"collector.fspath == topdir\"),\n                (\"pytest_make_collect_report\", \"collector.fspath == topdir\"),\n                (\"pytest_collectstart\", \"collector.fspath == p\"),\n                (\"pytest_make_collect_report\", \"collector.fspath == p\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.result[0].name == 'test_func'\"),\n            ]\n        )\n        # ensure we are reporting the collection of the single test item (#2464)\n        assert [x.name for x in self.get_reported_items(hookrec)] == [\"test_func\"]",
            "def test_ignore_collect_not_called_on_argument(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            def pytest_ignore_collect(path, config):\n                return True\n        \"\"\"\n        )\n        p = testdir.makepyfile(\"def test_hello(): pass\")\n        result = testdir.runpytest(p)\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n        result = testdir.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines([\"*collected 0 items*\"])",
            "def pytest_collect_file(self, path, parent):\n                if not path.basename.startswith(\".\"):\n                    # Ignore hidden files, e.g. .testmondata.\n                    wascalled.append(path)",
            "def test_collect_topdir(self, testdir):\n        p = testdir.makepyfile(\"def test_func(): pass\")\n        id = \"::\".join([p.basename, \"test_func\"])\n        # XXX migrate to collectonly? (see below)\n        config = testdir.parseconfig(id)\n        topdir = testdir.tmpdir\n        rcol = Session(config)\n        assert topdir == rcol.fspath\n        # rootid = rcol.nodeid\n        # root2 = rcol.perform_collect([rcol.nodeid], genitems=False)[0]\n        # assert root2 == rcol, rootid\n        colitems = rcol.perform_collect([rcol.nodeid], genitems=False)\n        assert len(colitems) == 1\n        assert colitems[0].fspath == p",
            "def test_collect_report_postprocessing(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import not_exists\n        \"\"\"\n        )\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.hookimpl(hookwrapper=True)\n            def pytest_make_collect_report():\n                outcome = yield\n                rep = outcome.get_result()\n                rep.headerlines += [\"header1\"]\n                outcome.force_result(rep)\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*ERROR collecting*\", \"*header1*\"])"
        ],
        "imports_info": [],
        "generated_tests": [
            "import pytest\nimport subprocess\n\nclass TestShortcut:\n    def test_collect_only_shortcut(self, testdir):\n        # create a simple test file\n        testdir.makepyfile(\"\"\"\n            def test_pass():\n                assert 1 == 1\n        \"\"\")\n\n        # run pytest with the new shortcut\n        result = subprocess.run(['pytest', '-c'], capture_output=True, text=True)\n\n        # run pytest with --collect-only for comparison\n        expected_result = subprocess.run(['pytest', '--collect-only'], capture_output=True, text=True)\n\n        # check if the outputs are the same\n        assert result.stdout == expected_result.stdout",
            "import pytest\nfrom _pytest.main import ExitCode\n\nclass TestShortcut:\n    def test_collect_only_shortcut(self, testdir):\n        # create a simple test file\n        testdir.makepyfile(\"\"\"\n            def test_foo():\n                assert 1\n        \"\"\")\n\n        # run pytest with the new shortcut\n        result = testdir.runpytest('-c')\n\n        # check that the tests were collected but not run\n        result.stdout.fnmatch_lines([\n            \"collected 1 item\",\n            \"*no tests ran in*\",\n        ])\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED",
            "import pytest\n\nclass TestShortcutCommand:\n    def test_shortcut_command(self, testdir):\n        # create a simple test file\n        testdir.makepyfile(\"\"\"\n            def test_func():\n                assert 1 == 1\n        \"\"\")\n\n        # run pytest with the new shortcut command\n        result = testdir.runpytest('-c')\n\n        # check that the tests were collected but not run\n        result.stdout.fnmatch_lines([\n            \"*collected 1 item*\",\n            \"*! no tests ran in*\",\n        ])",
            "import pytest\nimport subprocess\n\nclass TestShortcutCommand:\n    def test_shortcut_command(self):\n        # Run the pytest --collect-only command\n        process = subprocess.Popen(['pytest', '--collect-only'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = process.communicate()\n        collect_only_output = stdout.decode()\n\n        # Run the new shortcut command\n        process = subprocess.Popen(['pytest', '-c'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = process.communicate()\n        shortcut_command_output = stdout.decode()\n\n        # Check if the outputs are the same\n        assert collect_only_output == shortcut_command_output",
            "import pytest\n\nclass TestShortcutCommand:\n    def test_shortcut_command(self, testdir):\n        # create a simple test\n        testdir.makepyfile(\"\"\"\n            def test_foo():\n                assert 1 == 1\n        \"\"\")\n\n        # run pytest with the new shortcut command\n        result = testdir.runpytest('-c')\n\n        # check that pytest collected 1 item\n        result.stdout.fnmatch_lines(['collected 1 item'])\n\n        # check that pytest did not run the test\n        assert '1 passed' not in result.stdout.str()"
        ]
    },
    {
        "repo": "pytest-dev/pytest",
        "instance_id": "pytest-dev__pytest-5413",
        "base_commit": "450d2646233c670654744d3d24330b69895bb9d2",
        "patch": "diff --git a/src/_pytest/_code/code.py b/src/_pytest/_code/code.py\n--- a/src/_pytest/_code/code.py\n+++ b/src/_pytest/_code/code.py\n@@ -534,13 +534,6 @@ def getrepr(\n         )\n         return fmt.repr_excinfo(self)\n \n-    def __str__(self):\n-        if self._excinfo is None:\n-            return repr(self)\n-        entry = self.traceback[-1]\n-        loc = ReprFileLocation(entry.path, entry.lineno + 1, self.exconly())\n-        return str(loc)\n-\n     def match(self, regexp):\n         \"\"\"\n         Check whether the regular expression 'regexp' is found in the string\n",
        "test_patch": "diff --git a/testing/code/test_excinfo.py b/testing/code/test_excinfo.py\n--- a/testing/code/test_excinfo.py\n+++ b/testing/code/test_excinfo.py\n@@ -333,18 +333,10 @@ def test_excinfo_exconly():\n     assert msg.endswith(\"world\")\n \n \n-def test_excinfo_repr():\n+def test_excinfo_repr_str():\n     excinfo = pytest.raises(ValueError, h)\n-    s = repr(excinfo)\n-    assert s == \"<ExceptionInfo ValueError tblen=4>\"\n-\n-\n-def test_excinfo_str():\n-    excinfo = pytest.raises(ValueError, h)\n-    s = str(excinfo)\n-    assert s.startswith(__file__[:-9])  # pyc file and $py.class\n-    assert s.endswith(\"ValueError\")\n-    assert len(s.split(\":\")) >= 3  # on windows it's 4\n+    assert repr(excinfo) == \"<ExceptionInfo ValueError tblen=4>\"\n+    assert str(excinfo) == \"<ExceptionInfo ValueError tblen=4>\"\n \n \n def test_excinfo_for_later():\n",
        "problem_statement": "str() on the pytest.raises context variable doesn't behave same as normal exception catch\nPytest 4.6.2, macOS 10.14.5\r\n\r\n```Python\r\ntry:\r\n    raise LookupError(\r\n        f\"A\\n\"\r\n        f\"B\\n\"\r\n        f\"C\"\r\n    )\r\nexcept LookupError as e:\r\n    print(str(e))\r\n```\r\nprints\r\n\r\n> A\r\n> B\r\n> C\r\n\r\nBut\r\n\r\n```Python\r\nwith pytest.raises(LookupError) as e:\r\n    raise LookupError(\r\n        f\"A\\n\"\r\n        f\"B\\n\"\r\n        f\"C\"\r\n    )\r\n\r\nprint(str(e))\r\n```\r\n\r\nprints\r\n\r\n> <console>:3: LookupError: A\r\n\r\nIn order to get the full error message, one must do `str(e.value)`, which is documented, but this is a different interaction. Any chance the behavior could be changed to eliminate this gotcha?\r\n\r\n-----\r\n\r\nPip list gives\r\n\r\n```\r\nPackage            Version  Location\r\n------------------ -------- ------------------------------------------------------\r\napipkg             1.5\r\nasn1crypto         0.24.0\r\natomicwrites       1.3.0\r\nattrs              19.1.0\r\naws-xray-sdk       0.95\r\nboto               2.49.0\r\nboto3              1.9.51\r\nbotocore           1.12.144\r\ncertifi            2019.3.9\r\ncffi               1.12.3\r\nchardet            3.0.4\r\nClick              7.0\r\ncodacy-coverage    1.3.11\r\ncolorama           0.4.1\r\ncoverage           4.5.3\r\ncryptography       2.6.1\r\ndecorator          4.4.0\r\ndocker             3.7.2\r\ndocker-pycreds     0.4.0\r\ndocutils           0.14\r\necdsa              0.13.2\r\nexecnet            1.6.0\r\nfuture             0.17.1\r\nidna               2.8\r\nimportlib-metadata 0.17\r\nipaddress          1.0.22\r\nJinja2             2.10.1\r\njmespath           0.9.4\r\njsondiff           1.1.1\r\njsonpickle         1.1\r\njsonschema         2.6.0\r\nMarkupSafe         1.1.1\r\nmock               3.0.4\r\nmore-itertools     7.0.0\r\nmoto               1.3.7\r\nneobolt            1.7.10\r\nneotime            1.7.4\r\nnetworkx           2.1\r\nnumpy              1.15.0\r\npackaging          19.0\r\npandas             0.24.2\r\npip                19.1.1\r\npluggy             0.12.0\r\nprompt-toolkit     2.0.9\r\npy                 1.8.0\r\npy2neo             4.2.0\r\npyaml              19.4.1\r\npycodestyle        2.5.0\r\npycparser          2.19\r\npycryptodome       3.8.1\r\nPygments           2.3.1\r\npyOpenSSL          19.0.0\r\npyparsing          2.4.0\r\npytest             4.6.2\r\npytest-cache       1.0\r\npytest-codestyle   1.4.0\r\npytest-cov         2.6.1\r\npytest-forked      1.0.2\r\npython-dateutil    2.7.3\r\npython-jose        2.0.2\r\npytz               2018.5\r\nPyYAML             5.1\r\nrequests           2.21.0\r\nrequests-mock      1.5.2\r\nresponses          0.10.6\r\ns3transfer         0.1.13\r\nsetuptools         41.0.1\r\nsix                1.11.0\r\nsqlite3worker      1.1.7\r\ntabulate           0.8.3\r\nurllib3            1.24.3\r\nwcwidth            0.1.7\r\nwebsocket-client   0.56.0\r\nWerkzeug           0.15.2\r\nwheel              0.33.1\r\nwrapt              1.11.1\r\nxlrd               1.1.0\r\nxmltodict          0.12.0\r\nzipp               0.5.1\r\n```\n",
        "hints_text": "> Any chance the behavior could be changed to eliminate this gotcha?\r\n\r\nWhat do you suggest?\r\n\r\nProxying through to the exceptions `__str__`?\nHi @fiendish,\r\n\r\nIndeed this is a bit confusing.\r\n\r\nCurrently `ExceptionInfo` objects (which is `pytest.raises` returns to the context manager) implements `__str__` like this:\r\n\r\nhttps://github.com/pytest-dev/pytest/blob/9f8b566ea976df3a3ea16f74b56dd6d4909b84ee/src/_pytest/_code/code.py#L537-L542\r\n\r\nI don't see much use for this, I would rather it didn't implement `__str__` at all and let `__repr__` take over, which would show something like:\r\n\r\n```\r\n<ExceptionInfo LookupError tb=10>\r\n```\r\n\r\nWhich makes it more obvious that this is not what the user intended with `str(e)` probably.\r\n\r\nSo I think a good solution is to simply delete the `__str__` method.\r\n\r\nThoughts?\r\n\r\nAlso, @fiendish which Python version are you using?\n> So I think a good solution is to simply delete the `__str__` method.\r\n\r\nMakes sense to me.\r\n\r\n\nPython 3.7.3\r\n\r\nMy ideal outcome would be for str(e) to act the same as str(e.value), but I can understand if that isn't desired.\n> My ideal outcome would be for str(e) to act the same as str(e.value), but I can understand if that isn't desired.\r\n\r\nI understand, but I think it is better to be explicit here, because users might use `print(e)` to see what `e` is, assume it is the exception value, and then get confused later when it actually isn't (an `isinstance` check or accessing `e.args`).\n+1 for deleting the current `__str__` implementation\r\n-1 for proxying it to the underlying `e.value`\r\n\r\nthe `ExceptionInfo` object is not the exception and anything that makes it look more like the exception is just going to add to the confusion",
        "created_at": "2019-06-06T15:21:20Z",
        "version": "4.6",
        "FAIL_TO_PASS": "[\"testing/code/test_excinfo.py::test_excinfo_repr_str\"]",
        "PASS_TO_PASS": "[\"testing/code/test_excinfo.py::test_excinfo_simple\", \"testing/code/test_excinfo.py::test_excinfo_getstatement\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_entries\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_entry_getsource\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_entry_getsource_in_construct\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_cut\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_filter\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_filter_selective[<lambda>-True]\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_filter_selective[<lambda>-False]\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_filter_selective[tracebackhide2-True]\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_filter_selective[tracebackhide3-False]\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_recursion_index\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_only_specific_recursion_errors\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_no_recursion_index\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_getcrashentry\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_getcrashentry_empty\", \"testing/code/test_excinfo.py::test_excinfo_exconly\", \"testing/code/test_excinfo.py::test_excinfo_for_later\", \"testing/code/test_excinfo.py::test_excinfo_errisinstance\", \"testing/code/test_excinfo.py::test_excinfo_no_sourcecode\", \"testing/code/test_excinfo.py::test_entrysource_Queue_example\", \"testing/code/test_excinfo.py::test_codepath_Queue_example\", \"testing/code/test_excinfo.py::test_match_succeeds\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_source\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_source_excinfo\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_source_not_existing\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_many_line_source_not_existing\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_source_failing_fullsource\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_local\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_local_with_error\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_local_with_exception_in_class_property\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_local_truncated\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_tracebackentry_lines\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_tracebackentry_lines2\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_tracebackentry_lines_var_kw_args\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_tracebackentry_short\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_tracebackentry_no\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_traceback_tbfilter\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_traceback_short_no_source\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_traceback_and_excinfo\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_traceback_with_invalid_cwd\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_excinfo_addouterr\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_excinfo_reprcrash\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_traceback_recursion\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_reprexcinfo_getrepr\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_reprexcinfo_unicode\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_toterminal_long\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_toterminal_long_missing_source\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_toterminal_long_incomplete_source\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_toterminal_long_filenames\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions0]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions1]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions2]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions3]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions4]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions5]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions6]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions7]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions8]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions9]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions10]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions11]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions12]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions13]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions14]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions15]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions16]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions17]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions18]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions19]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions20]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions21]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions22]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_format_excinfo[reproptions23]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_traceback_repr_style\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_exc_chain_repr\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_exc_repr_chain_suppression[from_none]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_exc_repr_chain_suppression[explicit_suppress]\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_exc_chain_repr_without_traceback[cause-The\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_exc_chain_repr_without_traceback[context-During\", \"testing/code/test_excinfo.py::TestFormattedExcinfo::test_exc_chain_repr_cycle\", \"testing/code/test_excinfo.py::test_repr_traceback_with_unicode[None-short]\", \"testing/code/test_excinfo.py::test_repr_traceback_with_unicode[None-long]\", \"testing/code/test_excinfo.py::test_repr_traceback_with_unicode[utf8-short]\", \"testing/code/test_excinfo.py::test_repr_traceback_with_unicode[utf8-long]\", \"testing/code/test_excinfo.py::test_repr_traceback_with_unicode[utf16-short]\", \"testing/code/test_excinfo.py::test_repr_traceback_with_unicode[utf16-long]\", \"testing/code/test_excinfo.py::test_exception_repr_extraction_error_on_recursion\", \"testing/code/test_excinfo.py::test_no_recursion_index_on_recursion_error\", \"testing/code/test_excinfo.py::TestTraceback_f_g_h::test_traceback_cut_excludepath\", \"testing/code/test_excinfo.py::test_match_raises_error\", \"testing/code/test_excinfo.py::test_cwd_deleted\"]",
        "environment_setup_commit": "d5843f89d3c008ddcb431adbc335b080a79e617e",
        "issue_title": "str() on the pytest.raises context variable doesn't behave same as normal exception catch",
        "test_file": "/home/fdse/wy/RepoCodeEdit/data/raw_repo_lite/pytest/testing/test_assertion.py",
        "searched_functions": [
            "def test_raise_assertion_error_raisin_repr(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        class RaisingRepr(object):\n            def __repr__(self):\n                raise Exception()\n        def test_raising_repr():\n            raise AssertionError(RaisingRepr())\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\"E       AssertionError: <unprintable AssertionError object>\"]\n    )",
            "def test_triple_quoted_string_issue113(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        def test_hello():\n            assert \"\" == '''\n    '''\"\"\"\n    )\n    result = testdir.runpytest(\"--fulltrace\")\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n    assert \"SyntaxError\" not in result.stdout.str()",
            "def test_traceback_failure(testdir):\n    p1 = testdir.makepyfile(\n        \"\"\"\n        def g():\n            return 2\n        def f(x):\n            assert x == g()\n        def test_onefails():\n            f(3)\n    \"\"\"\n    )\n    result = testdir.runpytest(p1, \"--tb=long\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_traceback_failure.py F*\",\n            \"====* FAILURES *====\",\n            \"____*____\",\n            \"\",\n            \"    def test_onefails():\",\n            \">       f(3)\",\n            \"\",\n            \"*test_*.py:6: \",\n            \"_ _ _ *\",\n            # \"\",\n            \"    def f(x):\",\n            \">       assert x == g()\",\n            \"E       assert 3 == 2\",\n            \"E        +  where 2 = g()\",\n            \"\",\n            \"*test_traceback_failure.py:4: AssertionError\",\n        ]\n    )\n\n    result = testdir.runpytest(p1)  # \"auto\"\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_traceback_failure.py F*\",\n            \"====* FAILURES *====\",\n            \"____*____\",\n            \"\",\n            \"    def test_onefails():\",\n            \">       f(3)\",\n            \"\",\n            \"*test_*.py:6: \",\n            \"\",\n            \"    def f(x):\",\n            \">       assert x == g()\",\n            \"E       assert 3 == 2\",\n            \"E        +  where 2 = g()\",\n            \"\",\n            \"*test_traceback_failure.py:4: AssertionError\",\n        ]\n    )",
            "def test_pytest_assertrepr_compare_called(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            values = []\n            def pytest_assertrepr_compare(op, left, right):\n                values.append((op, left, right))\n\n            @pytest.fixture\n            def list(request):\n                return values\n        \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n            def test_hello():\n                assert 0 == 1\n            def test_check(list):\n                assert list == [(\"==\", 0, 1)]\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_hello*FAIL*\", \"*test_check*PASS*\"])",
            "def test_raise_unprintable_assertion_error(testdir):\n    testdir.makepyfile(\n        r\"\"\"\n        def test_raise_assertion_error():\n            raise AssertionError('\\xff')\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [r\">       raise AssertionError('\\xff')\", \"E       AssertionError: *\"]\n    )",
            "def test_repr_no_exc(self):\n        expl = \" \".join(callequal(\"foo\", \"bar\"))\n        assert \"raised in repr()\" not in expl",
            "def test_warn_missing(testdir):\n    testdir.makepyfile(\"\")\n    result = testdir.run(sys.executable, \"-OO\", \"-m\", \"pytest\", \"-h\")\n    result.stderr.fnmatch_lines([\"*WARNING*assert statements are not executed*\"])\n    result = testdir.run(sys.executable, \"-OO\", \"-m\", \"pytest\")\n    result.stderr.fnmatch_lines([\"*WARNING*assert statements are not executed*\"])",
            "def test_special_chars_full(self, testdir):\n        # Issue 453, for the bug this would raise IndexError\n        testdir.makepyfile(\n            \"\"\"\n            def test_foo():\n                assert '\\\\n}' == ''\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == 1\n        result.stdout.fnmatch_lines([\"*AssertionError*\"])",
            "def test_sequence_comparison_uses_repr(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        def test_hello():\n            x = set(\"hello x\")\n            y = set(\"hello y\")\n            assert x == y\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*def test_hello():*\",\n            \"*assert x == y*\",\n            \"*E*Extra items*left*\",\n            \"*E*'x'*\",\n            \"*E*Extra items*right*\",\n            \"*E*'y'*\",\n        ]\n    )",
            "def test_assert_indirect_tuple_no_warning(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        def test_tuple():\n            tpl = ('foo', 'bar')\n            assert tpl\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rw\")\n    output = \"\\n\".join(result.stdout.lines)\n    assert \"WR1\" not in output"
        ],
        "imports_info": [],
        "generated_tests": [
            "import pytest\n\ndef test_pytest_raises_str():\n    error_message = \"A\\nB\\nC\"\n    with pytest.raises(LookupError) as e:\n        raise LookupError(error_message)\n    assert str(e.value) == error_message, \"str() on pytest.raises context variable should return full error message\"",
            "import pytest\n\ndef test_pytest_raises():\n    try:\n        with pytest.raises(LookupError) as e:\n            raise LookupError(\n                f\"A\\n\"\n                f\"B\\n\"\n                f\"C\"\n            )\n        assert str(e.value) == \"A\\nB\\nC\"\n    except Exception as e:\n        assert False, f\"Test failed: {e}\"",
            "import pytest\n\ndef test_str_on_pytest_raises():\n    try:\n        with pytest.raises(LookupError) as e:\n            raise LookupError(\n                f\"A\\n\"\n                f\"B\\n\"\n                f\"C\"\n            )\n        assert str(e) == \"A\\nB\\nC\"\n    except AssertionError:\n        assert str(e.value) == \"A\\nB\\nC\"",
            "import pytest\n\ndef test_exception_message():\n    try:\n        with pytest.raises(LookupError) as e:\n            raise LookupError(\n                f\"A\\n\"\n                f\"B\\n\"\n                f\"C\"\n            )\n        assert str(e) == \"A\\nB\\nC\"\n    except AssertionError:\n        print(\"Test failed: str(e) did not print the full error message.\")\n    else:\n        print(\"Test passed: str(e) printed the full error message.\")",
            "import pytest\n\ndef test_str_on_pytest_raises():\n    # Define a multi-line error message\n    error_message = \"A\\nB\\nC\"\n\n    # Raise an exception with the error message and catch it\n    try:\n        raise LookupError(error_message)\n    except LookupError as e:\n        # Check if str(e) returns the full error message\n        assert str(e) == error_message\n\n    # Raise an exception with the error message using pytest.raises\n    with pytest.raises(LookupError) as e:\n        raise LookupError(error_message)\n\n    # Check if str(e.value) returns the full error message\n    assert str(e.value) == error_message"
        ]
    },
    {
        "repo": "pytest-dev/pytest",
        "instance_id": "pytest-dev__pytest-7490",
        "base_commit": "7f7a36478abe7dd1fa993b115d22606aa0e35e88",
        "patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -231,17 +231,14 @@ def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n \n @hookimpl(tryfirst=True)\n def pytest_runtest_setup(item: Item) -> None:\n-    item._store[skipped_by_mark_key] = False\n-\n     skipped = evaluate_skip_marks(item)\n+    item._store[skipped_by_mark_key] = skipped is not None\n     if skipped:\n-        item._store[skipped_by_mark_key] = True\n         skip(skipped.reason)\n \n-    if not item.config.option.runxfail:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-        if xfailed and not xfailed.run:\n-            xfail(\"[NOTRUN] \" + xfailed.reason)\n+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    if xfailed and not item.config.option.runxfail and not xfailed.run:\n+        xfail(\"[NOTRUN] \" + xfailed.reason)\n \n \n @hookimpl(hookwrapper=True)\n@@ -250,12 +247,16 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n     if xfailed is None:\n         item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n \n-    if not item.config.option.runxfail:\n-        if xfailed and not xfailed.run:\n-            xfail(\"[NOTRUN] \" + xfailed.reason)\n+    if xfailed and not item.config.option.runxfail and not xfailed.run:\n+        xfail(\"[NOTRUN] \" + xfailed.reason)\n \n     yield\n \n+    # The test run may have added an xfail mark dynamically.\n+    xfailed = item._store.get(xfailed_key, None)\n+    if xfailed is None:\n+        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+\n \n @hookimpl(hookwrapper=True)\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n",
        "test_patch": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -1,6 +1,7 @@\n import sys\n \n import pytest\n+from _pytest.pytester import Testdir\n from _pytest.runner import runtestprotocol\n from _pytest.skipping import evaluate_skip_marks\n from _pytest.skipping import evaluate_xfail_marks\n@@ -425,6 +426,33 @@ def test_this2(arg):\n         result = testdir.runpytest(p)\n         result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n \n+    def test_dynamic_xfail_set_during_runtest_failed(self, testdir: Testdir) -> None:\n+        # Issue #7486.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(xfailed=1)\n+\n+    def test_dynamic_xfail_set_during_runtest_passed_strict(\n+        self, testdir: Testdir\n+    ) -> None:\n+        # Issue #7486.\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            def test_this(request):\n+                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\", strict=True))\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(p)\n+        result.assert_outcomes(failed=1)\n+\n     @pytest.mark.parametrize(\n         \"expected, actual, matchline\",\n         [\n",
        "problem_statement": "Pytest 6: Dynamically adding xfail marker in test no longer ignores failure\n<!--\r\nThanks for submitting an issue!\r\n\r\nHere's a quick checklist for what to provide:\r\n-->\r\n\r\n## Description\r\n\r\nWith pytest 5.x, we can dynamically add an xfail to a test `request` object using `request.node.add_marker(mark)` (see example below). In 5.x this treated the failing test like a a test marked statically with an `xfail`. With 6.0.0rc0 it raises. \r\n\r\n## Versions\r\n\r\n<details>\r\n\r\n```\r\n$ pip list\r\nPackage                       Version                         Location                                                      \r\n----------------------------- ------------------------------- --------------------------------------------------------------\r\na                             1.0                             \r\naioftp                        0.13.0                          \r\naiohttp                       3.6.2                           \r\nalabaster                     0.7.12                          \r\napipkg                        1.5                             \r\naplus                         0.11.0                          \r\nappdirs                       1.4.3                           \r\nappnope                       0.1.0                           \r\narrow                         0.15.7                          \r\naspy.yaml                     1.3.0                           \r\nastropy                       3.2.3                           \r\nasv                           0.4.1                           \r\nasync-timeout                 3.0.1                           \r\natomicwrites                  1.3.0                           \r\nattrs                         19.1.0                          \r\naws-sam-translator            1.15.1                          \r\naws-xray-sdk                  0.95                            \r\nBabel                         2.7.0                           \r\nbackcall                      0.1.0                           \r\nbinaryornot                   0.4.4                           \r\nblack                         19.10b0                         \r\nbleach                        3.1.0                           \r\nblurb                         1.0.7                           \r\nbokeh                         1.3.4                           \r\nboto                          2.49.0                          \r\nboto3                         1.7.84                          \r\nbotocore                      1.10.84                         \r\nbqplot                        0.12.12                         \r\nbranca                        0.3.1                           \r\ncachetools                    4.1.0                           \r\ncertifi                       2019.9.11                       \r\ncffi                          1.13.2                          \r\ncfgv                          2.0.1                           \r\ncfn-lint                      0.25.0                          \r\ncftime                        1.0.4.2                         \r\nchardet                       3.0.4                           \r\nClick                         7.0                             \r\nclick-plugins                 1.1.1                           \r\ncligj                         0.5.0                           \r\ncloudpickle                   1.2.2                           \r\ncolorama                      0.4.3                           \r\ncolorcet                      2.0.2                           \r\ncoloredlogs                   14.0                            \r\ncookiecutter                  1.7.2                           \r\ncookies                       2.2.1                           \r\ncoverage                      4.5.4                           \r\ncryptography                  2.8                             \r\ncycler                        0.10.0                          \r\nCython                        3.0a5                           \r\ncytoolz                       0.10.1                          \r\ndask                          2.4.0                           /Users/taugspurger/Envs/pandas-dev/lib/python3.7/site-packages\r\nDateTime                      4.3                             \r\ndecorator                     4.4.0                           \r\ndefusedxml                    0.6.0                           \r\nDeprecated                    1.2.7                           \r\ndistributed                   2.4.0                           \r\ndocker                        4.1.0                           \r\ndocutils                      0.15.2                          \r\necdsa                         0.14.1                          \r\nentrypoints                   0.3                             \r\net-xmlfile                    1.0.1                           \r\nexecnet                       1.7.1                           \r\nfastparquet                   0.3.3                           /Users/taugspurger/sandbox/fastparquet                        \r\nfeedparser                    5.2.1                           \r\nFiona                         1.8.8                           \r\nflake8                        3.7.9                           \r\nflake8-rst                    0.7.1                           \r\nfletcher                      0.3.1                           \r\nflit                          2.1.0                           \r\nflit-core                     2.1.0                           \r\nfsspec                        0.7.4                           \r\nfuture                        0.18.2                          \r\ngcsfs                         0.6.2                           \r\ngeopandas                     0.6.0+1.g95b8e1a.dirty          /Users/taugspurger/sandbox/geopandas                          \r\ngitdb2                        2.0.5                           \r\nGitPython                     3.0.2                           \r\ngoogle-auth                   1.16.1                          \r\ngoogle-auth-oauthlib          0.4.1                           \r\ngraphviz                      0.13                            \r\nh5py                          2.10.0                          \r\nHeapDict                      1.0.1                           \r\nholoviews                     1.12.6                          \r\nhumanfriendly                 8.1                             \r\nhunter                        3.1.3                           \r\nhvplot                        0.5.2                           \r\nhypothesis                    4.36.2                          \r\nidentify                      1.4.7                           \r\nidna                          2.8                             \r\nimagesize                     1.1.0                           \r\nimportlib-metadata            0.23                            \r\nimportlib-resources           1.0.2                           \r\niniconfig                     1.0.0                           \r\nintake                        0.5.3                           \r\nipydatawidgets                4.0.1                           \r\nipykernel                     5.1.2                           \r\nipyleaflet                    0.13.0                          \r\nipympl                        0.5.6                           \r\nipython                       7.11.1                          \r\nipython-genutils              0.2.0                           \r\nipyvolume                     0.5.2                           \r\nipyvue                        1.3.2                           \r\nipyvuetify                    1.4.0                           \r\nipywebrtc                     0.5.0                           \r\nipywidgets                    7.5.1                           \r\nisort                         4.3.21                          \r\njdcal                         1.4.1                           \r\njedi                          0.16.0                          \r\nJinja2                        2.11.2                          \r\njinja2-time                   0.2.0                           \r\njmespath                      0.9.4                           \r\njoblib                        0.14.1                          \r\njson5                         0.9.4                           \r\njsondiff                      1.1.1                           \r\njsonpatch                     1.24                            \r\njsonpickle                    1.2                             \r\njsonpointer                   2.0                             \r\njsonschema                    3.0.2                           \r\njupyter                       1.0.0                           \r\njupyter-client                5.3.3                           \r\njupyter-console               6.0.0                           \r\njupyter-core                  4.5.0                           \r\njupyterlab                    2.1.2                           \r\njupyterlab-server             1.1.4                           \r\nkiwisolver                    1.1.0                           \r\nline-profiler                 2.1.1                           \r\nllvmlite                      0.33.0                          \r\nlocket                        0.2.0                           /Users/taugspurger/sandbox/locket.py                          \r\nlxml                          4.5.0                           \r\nmanhole                       1.6.0                           \r\nMarkdown                      3.1.1                           \r\nMarkupSafe                    1.1.1                           \r\nmatplotlib                    3.2.2                           \r\nmccabe                        0.6.1                           \r\nmemory-profiler               0.55.0                          \r\nmistune                       0.8.4                           \r\nmock                          3.0.5                           \r\nmore-itertools                7.2.0                           \r\nmoto                          1.3.6                           \r\nmsgpack                       0.6.2                           \r\nmultidict                     4.5.2                           \r\nmunch                         2.3.2                           \r\nmypy                          0.730                           \r\nmypy-extensions               0.4.1                           \r\nnbconvert                     5.6.0                           \r\nnbformat                      4.4.0                           \r\nnbsphinx                      0.4.2                           \r\nnest-asyncio                  1.3.3                           \r\nnodeenv                       1.3.3                           \r\nnotebook                      6.0.1                           \r\nnumexpr                       2.7.1                           \r\nnumpy                         1.19.0                          \r\nnumpydoc                      1.0.0.dev0                      \r\noauthlib                      3.1.0                           \r\nodfpy                         1.4.0                           \r\nopenpyxl                      3.0.3                           \r\npackaging                     20.4                            \r\npandas                        1.1.0.dev0+1758.g035e1fe831     /Users/taugspurger/sandbox/pandas                             \r\npandas-sphinx-theme           0.0.1.dev0                      /Users/taugspurger/sandbox/pandas-sphinx-theme                \r\npandocfilters                 1.4.2                           \r\nparam                         1.9.2                           \r\nparfive                       1.0.0                           \r\nparso                         0.6.0                           \r\npartd                         1.0.0                           \r\npathspec                      0.8.0                           \r\npatsy                         0.5.1                           \r\npexpect                       4.7.0                           \r\npickleshare                   0.7.5                           \r\nPillow                        6.1.0                           \r\npip                           20.0.2                          \r\npluggy                        0.13.0                          \r\npoyo                          0.5.0                           \r\npre-commit                    1.18.3                          \r\nprogressbar2                  3.51.3                          \r\nprometheus-client             0.7.1                           \r\nprompt-toolkit                2.0.9                           \r\npsutil                        5.6.3                           \r\nptyprocess                    0.6.0                           \r\npy                            1.9.0                           \r\npyaml                         20.4.0                          \r\npyarrow                       0.16.0                          \r\npyasn1                        0.4.7                           \r\npyasn1-modules                0.2.8                           \r\npycodestyle                   2.5.0                           \r\npycparser                     2.19                            \r\npycryptodome                  3.9.8                           \r\npyct                          0.4.6                           \r\npydata-sphinx-theme           0.1.1                           \r\npydeps                        1.9.0                           \r\npyflakes                      2.1.1                           \r\nPyGithub                      1.44.1                          \r\nPygments                      2.4.2                           \r\nPyJWT                         1.7.1                           \r\npyparsing                     2.4.2                           \r\npyproj                        2.4.0                           \r\npyrsistent                    0.15.4                          \r\npytest                        5.4.3                           \r\npytest-asyncio                0.10.0                          \r\npytest-cov                    2.8.1                           \r\npytest-cover                  3.0.0                           \r\npytest-forked                 1.0.2                           \r\npytest-repeat                 0.8.0                           \r\npytest-xdist                  1.29.0                          \r\npython-boilerplate            0.1.0                           \r\npython-dateutil               2.8.0                           \r\npython-jose                   2.0.2                           \r\npython-jsonrpc-server         0.3.2                           \r\npython-language-server        0.31.4                          \r\npython-slugify                4.0.1                           \r\npython-utils                  2.4.0                           \r\npythreejs                     2.2.0                           \r\npytoml                        0.1.21                          \r\npytz                          2019.2                          \r\npyviz-comms                   0.7.2                           \r\nPyYAML                        5.1.2                           \r\npyzmq                         18.1.0                          \r\nqtconsole                     4.5.5                           \r\nregex                         2020.6.8                        \r\nrequests                      2.24.0                          \r\nrequests-oauthlib             1.3.0                           \r\nresponses                     0.10.6                          \r\nrsa                           4.0                             \r\nrstcheck                      3.3.1                           \r\ns3fs                          0.4.2                           \r\ns3transfer                    0.1.13                          \r\nscikit-learn                  0.22.2.post1                    \r\nscipy                         1.3.1                           \r\nseaborn                       0.9.0                           \r\nSend2Trash                    1.5.0                           \r\nsetuptools                    49.2.0                          \r\nShapely                       1.6.4.post2                     \r\nsix                           1.12.0                          \r\nsmmap2                        2.0.5                           \r\nsnakeviz                      2.0.1                           \r\nsnowballstemmer               1.9.1                           \r\nsortedcontainers              2.1.0                           \r\nsparse                        0.10.0                          \r\nSphinx                        3.1.1                           \r\nsphinxcontrib-applehelp       1.0.2                           \r\nsphinxcontrib-devhelp         1.0.2                           \r\nsphinxcontrib-htmlhelp        1.0.3                           \r\nsphinxcontrib-jsmath          1.0.1                           \r\nsphinxcontrib-qthelp          1.0.3                           \r\nsphinxcontrib-serializinghtml 1.1.4                           \r\nsphinxcontrib-websupport      1.1.2                           \r\nsphinxcontrib.youtube         0.1.2                           \r\nSQLAlchemy                    1.3.11                          \r\nsshpubkeys                    3.1.0                           \r\nstatsmodels                   0.10.2                          \r\nstdlib-list                   0.6.0                           \r\nsunpy                         1.1.dev518+gcad2d473f.d20191103 /Users/taugspurger/sandbox/sunpy                              \r\ntables                        3.6.1                           \r\ntabulate                      0.8.6                           \r\ntblib                         1.4.0                           \r\nterminado                     0.8.2                           \r\ntest                          1.0.0                           \r\ntestpath                      0.4.2                           \r\ntext-unidecode                1.3                             \r\nthrift                        0.13.0                          \r\ntoml                          0.10.0                          \r\ntoolz                         0.10.0                          \r\ntornado                       6.0.3                           \r\ntqdm                          4.37.0                          \r\ntraitlets                     4.3.2                           \r\ntraittypes                    0.2.1                           \r\ntyped-ast                     1.4.0                           \r\ntyping-extensions             3.7.4                           \r\nujson                         1.35                            \r\nurllib3                       1.25.5                          \r\nvaex                          3.0.0                           \r\nvaex-arrow                    0.5.1                           \r\nvaex-astro                    0.7.0                           \r\nvaex-core                     2.0.2                           \r\nvaex-hdf5                     0.6.0                           \r\nvaex-jupyter                  0.5.1.post0                     \r\nvaex-ml                       0.9.0                           \r\nvaex-server                   0.3.1                           \r\nvaex-viz                      0.4.0                           \r\nvirtualenv                    16.7.5                          \r\nwcwidth                       0.1.7                           \r\nwebencodings                  0.5.1                           \r\nwebsocket-client              0.56.0                          \r\nWerkzeug                      0.16.0                          \r\nwheel                         0.34.2                          \r\nwidgetsnbextension            3.5.1                           \r\nwrapt                         1.11.2                          \r\nxarray                        0.14.1+36.gb3d3b448             /Users/taugspurger/sandbox/xarray                             \r\nxlwt                          1.3.0                           \r\nxmltodict                     0.12.0                          \r\nyarl                          1.3.0                           \r\nzict                          1.0.0                           \r\nzipp                          0.6.0                           \r\nzope.interface                4.7.1                           \r\n```\r\n\r\n</details>\r\n\r\n- [ ] pytest and operating system versions\r\n\r\nPytest 6.0.1rc0 and MacOS 10.14.5\r\n\r\n```python\r\n# file: test_foo.py\r\nimport pytest\r\n\r\n\r\ndef test_xfail_test(request):\r\n    mark = pytest.mark.xfail(reason=\"xfail\")\r\n    request.node.add_marker(mark)\r\n    assert 0\r\n```\r\n\r\nWith 5.4.3\r\n\r\n```\r\n\r\n$ pytest -rsx test_foo.py\r\n=============================================================================== test session starts ================================================================================\r\nplatform darwin -- Python 3.7.6, pytest-5.4.3, py-1.9.0, pluggy-0.13.0\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/Users/taugspurger/sandbox/.hypothesis/examples')\r\nrootdir: /Users/taugspurger/sandbox\r\nplugins: xdist-1.29.0, hypothesis-4.36.2, forked-1.0.2, repeat-0.8.0, asyncio-0.10.0, cov-2.8.1\r\ncollected 1 item\r\n\r\ntest_foo.py x                                                                                                                                                                [100%]\r\n\r\n============================================================================= short test summary info ==============================================================================\r\nXFAIL test_foo.py::test_xfail_test\r\n  xfail\r\n================================================================================ 1 xfailed in 0.07s ================================================================================\r\n```\r\n\r\nWith 6.0.0rc0\r\n\r\n```\r\n$ pytest -rsx test_foo.py\r\n=============================================================================== test session starts ================================================================================\r\nplatform darwin -- Python 3.7.6, pytest-6.0.0rc1, py-1.9.0, pluggy-0.13.0\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/Users/taugspurger/sandbox/.hypothesis/examples')\r\nrootdir: /Users/taugspurger/sandbox\r\nplugins: xdist-1.29.0, hypothesis-4.36.2, forked-1.0.2, repeat-0.8.0, asyncio-0.10.0, cov-2.8.1\r\ncollected 1 item\r\n\r\ntest_foo.py F                                                                                                                                                                [100%]\r\n\r\n===================================================================================== FAILURES =====================================================================================\r\n_________________________________________________________________________________ test_xfail_test __________________________________________________________________________________\r\n\r\nrequest = <FixtureRequest for <Function test_xfail_test>>\r\n\r\n    def test_xfail_test(request):\r\n        mark = pytest.mark.xfail(reason=\"xfail\")\r\n        request.node.add_marker(mark)\r\n>       assert 0\r\nE       assert 0\r\n\r\ntest_foo.py:7: AssertionError\r\n```\r\n\n",
        "hints_text": "Thanks for testing the release candidate! This is probably a regression in c9737ae914891027da5f0bd39494dd51a3b3f19f, will fix.",
        "created_at": "2020-07-13T22:20:10Z",
        "version": "6.0",
        "FAIL_TO_PASS": "[\"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_runtest_failed\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_runtest_passed_strict\"]",
        "PASS_TO_PASS": "[\"testing/test_skipping.py::test_importorskip\", \"testing/test_skipping.py::TestEvaluation::test_no_marker\", \"testing/test_skipping.py::TestEvaluation::test_marked_xfail_no_args\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_no_args\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_with_reason\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice2\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_boolean_without_reason\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_invalid_boolean\", \"testing/test_skipping.py::TestEvaluation::test_skipif_class\", \"testing/test_skipping.py::TestXFail::test_xfail_simple[True]\", \"testing/test_skipping.py::TestXFail::test_xfail_simple[False]\", \"testing/test_skipping.py::TestXFail::test_xfail_xpassed\", \"testing/test_skipping.py::TestXFail::test_xfail_using_platform\", \"testing/test_skipping.py::TestXFail::test_xfail_xpassed_strict\", \"testing/test_skipping.py::TestXFail::test_xfail_run_anyway\", \"testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input0-expected0]\", \"testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input1-expected1]\", \"testing/test_skipping.py::TestXFail::test_xfail_evalfalse_but_fails\", \"testing/test_skipping.py::TestXFail::test_xfail_not_report_default\", \"testing/test_skipping.py::TestXFail::test_xfail_not_run_xfail_reporting\", \"testing/test_skipping.py::TestXFail::test_xfail_not_run_no_setup_run\", \"testing/test_skipping.py::TestXFail::test_xfail_xpass\", \"testing/test_skipping.py::TestXFail::test_xfail_imperative\", \"testing/test_skipping.py::TestXFail::test_xfail_imperative_in_setup_function\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_no_run\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_funcarg_setup\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-TypeError-*1\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[(AttributeError,\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-IndexError-*1\", \"testing/test_skipping.py::TestXFail::test_strict_sanity\", \"testing/test_skipping.py::TestXFail::test_strict_xfail[True]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail[False]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_condition[True]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_condition[False]\", \"testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[True]\", \"testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[False]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[true]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[false]\", \"testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_setup_issue9\", \"testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_teardown_issue9\", \"testing/test_skipping.py::TestSkip::test_skip_class\", \"testing/test_skipping.py::TestSkip::test_skips_on_false_string\", \"testing/test_skipping.py::TestSkip::test_arg_as_reason\", \"testing/test_skipping.py::TestSkip::test_skip_no_reason\", \"testing/test_skipping.py::TestSkip::test_skip_with_reason\", \"testing/test_skipping.py::TestSkip::test_only_skips_marked_test\", \"testing/test_skipping.py::TestSkip::test_strict_and_skip\", \"testing/test_skipping.py::TestSkipif::test_skipif_conditional\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting[\\\"hasattr(sys,\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting[True,\", \"testing/test_skipping.py::TestSkipif::test_skipif_using_platform\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[skipif-SKIP-skipped]\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[xfail-XPASS-xpassed]\", \"testing/test_skipping.py::test_skip_not_report_default\", \"testing/test_skipping.py::test_skipif_class\", \"testing/test_skipping.py::test_skipped_reasons_functional\", \"testing/test_skipping.py::test_skipped_folding\", \"testing/test_skipping.py::test_reportchars\", \"testing/test_skipping.py::test_reportchars_error\", \"testing/test_skipping.py::test_reportchars_all\", \"testing/test_skipping.py::test_reportchars_all_error\", \"testing/test_skipping.py::test_errors_in_xfail_skip_expressions\", \"testing/test_skipping.py::test_xfail_skipif_with_globals\", \"testing/test_skipping.py::test_default_markers\", \"testing/test_skipping.py::test_xfail_test_setup_exception\", \"testing/test_skipping.py::test_imperativeskip_on_xfail_test\", \"testing/test_skipping.py::TestBooleanCondition::test_skipif\", \"testing/test_skipping.py::TestBooleanCondition::test_skipif_noreason\", \"testing/test_skipping.py::TestBooleanCondition::test_xfail\", \"testing/test_skipping.py::test_xfail_item\", \"testing/test_skipping.py::test_module_level_skip_error\", \"testing/test_skipping.py::test_module_level_skip_with_allow_module_level\", \"testing/test_skipping.py::test_invalid_skip_keyword_parameter\", \"testing/test_skipping.py::test_mark_xfail_item\", \"testing/test_skipping.py::test_summary_list_after_errors\", \"testing/test_skipping.py::test_relpath_rootdir\"]",
        "environment_setup_commit": "634cde9506eb1f48dec3ec77974ee8dc952207c6",
        "issue_title": "Pytest 6: Dynamically adding xfail marker in test no longer ignores failure",
        "test_file": "/home/fdse/wy/RepoCodeEdit/data/raw_repo_lite/pytest/testing/test_mark.py",
        "searched_functions": [
            "def test_mark_with_wrong_marker(self, testdir):\n        reprec = testdir.inline_runsource(\n            \"\"\"\n                import pytest\n                class pytestmark(object):\n                    pass\n                def test_func():\n                    pass\n        \"\"\"\n        )\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n        assert \"TypeError\" in str(values[0].longrepr)",
            "def test_marker_without_description(testdir):\n    testdir.makefile(\n        \".cfg\",\n        setup=\"\"\"\n        [tool:pytest]\n        markers=slow\n    \"\"\",\n    )\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        pytest.mark.xfail('FAIL')\n    \"\"\"\n    )\n    ftdir = testdir.mkdir(\"ft1_dummy\")\n    testdir.tmpdir.join(\"conftest.py\").move(ftdir.join(\"conftest.py\"))\n    rec = testdir.runpytest(\"--strict-markers\")\n    rec.assert_outcomes()",
            "def test_marker_expr_eval_failure_handling(testdir, expr):\n    foo = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.internal_err\n        def test_foo():\n            pass\n        \"\"\"\n    )\n    expected = \"ERROR: Wrong expression passed to '-m': {}: *\".format(expr)\n    result = testdir.runpytest(foo, \"-m\", expr)\n    result.stderr.fnmatch_lines([expected])\n    assert result.ret == ExitCode.USAGE_ERROR",
            "def test_marked_class_run_twice(testdir):\n    \"\"\"Test fails file is run twice that contains marked class.\n    See issue#683.\n    \"\"\"\n    py_file = testdir.makepyfile(\n        \"\"\"\n    import pytest\n    @pytest.mark.parametrize('abc', [1, 2, 3])\n    class Test1(object):\n        def test_1(self, abc):\n            assert abc in [1, 2, 3]\n    \"\"\"\n    )\n    file_name = os.path.basename(py_file.strpath)\n    rec = testdir.inline_run(file_name, file_name)\n    rec.assertoutcome(passed=6)",
            "def test_keyword_added_for_session(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            def pytest_collection_modifyitems(session):\n                session.add_marker(\"mark1\")\n                session.add_marker(pytest.mark.mark2)\n                session.add_marker(pytest.mark.mark3)\n                pytest.raises(ValueError, lambda:\n                        session.add_marker(10))\n        \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n            def test_some(request):\n                assert \"mark1\" in request.keywords\n                assert \"mark2\" in request.keywords\n                assert \"mark3\" in request.keywords\n                assert 10 not in request.keywords\n                marker = request.node.get_closest_marker(\"mark1\")\n                assert marker.name == \"mark1\"\n                assert marker.args == ()\n                assert marker.kwargs == {}\n        \"\"\"\n        )\n        reprec = testdir.inline_run(\"-m\", \"mark1\")\n        reprec.assertoutcome(passed=1)",
            "def test_mark_dynamically_in_funcarg(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.hello)\n            def pytest_terminal_summary(terminalreporter):\n                values = terminalreporter.stats['passed']\n                terminalreporter._tw.line(\"keyword: %s\" % values[0].keywords)\n        \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n            def test_func(arg):\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"keyword: *hello*\"])",
            "def test_ini_markers(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        markers =\n            a1: this is a webtest marker\n            a2: this is a smoke marker\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        def test_markers(pytestconfig):\n            markers = pytestconfig.getini(\"markers\")\n            print(markers)\n            assert len(markers) >= 2\n            assert markers[0].startswith(\"a1:\")\n            assert markers[1].startswith(\"a2:\")\n    \"\"\"\n    )\n    rec = testdir.inline_run()\n    rec.assertoutcome(passed=1)",
            "def test_no_marker_match_on_unmarked_names(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.shouldmatch\n            def test_marked():\n                assert 1\n\n            def test_unmarked():\n                assert 1\n        \"\"\"\n        )\n        reprec = testdir.inline_run(\"-m\", \"test_unmarked\", p)\n        passed, skipped, failed = reprec.listoutcomes()\n        assert len(passed) + len(skipped) + len(failed) == 0\n        dlist = reprec.getcalls(\"pytest_deselected\")\n        deselected_tests = dlist[0].items\n        assert len(deselected_tests) == 2",
            "def test_pytest_mark_notcallable(self) -> None:\n        mark = Mark()\n        with pytest.raises(TypeError):\n            mark()",
            "def test_parameterset_for_fail_at_collect(testdir):\n    testdir.makeini(\n        \"\"\"\n    [pytest]\n    {}=fail_at_collect\n    \"\"\".format(\n            EMPTY_PARAMETERSET_OPTION\n        )\n    )\n\n    config = testdir.parseconfig()\n    from _pytest.mark import pytest_configure, get_empty_parameterset_mark\n\n    pytest_configure(config)\n\n    with pytest.raises(\n        Collector.CollectError,\n        match=r\"Empty parameter set in 'pytest_configure' at line \\d\\d+\",\n    ):\n        get_empty_parameterset_mark(config, [\"a\"], pytest_configure)\n\n    p1 = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"empty\", [])\n        def test():\n            pass\n        \"\"\"\n    )\n    result = testdir.runpytest(str(p1))\n    result.stdout.fnmatch_lines(\n        [\n            \"collected 0 items / 1 error\",\n            \"* ERROR collecting test_parameterset_for_fail_at_collect.py *\",\n            \"Empty parameter set in 'test' at line 3\",\n            \"*= 1 error in *\",\n        ]\n    )\n    assert result.ret == ExitCode.INTERRUPTED"
        ],
        "imports_info": [],
        "generated_tests": [
            "import pytest\n\nclass TestDynamicXfail:\n    def test_xfail_marker(self):\n        try:\n            @pytest.mark.xfail(reason=\"xfail\")\n            def test_func():\n                assert 0\n            pytest.main(['-k', 'test_func'])\n            assert False, \"Expected to raise an error but it didn't\"\n        except Exception as e:\n            assert str(e) == 'xfail', 'Unexpected error message: {}'.format(e)",
            "import pytest\n\nclass TestXfailMarker:\n    def test_xfail_marker(self):\n        def test_func(request):\n            mark = pytest.mark.xfail(reason=\"xfail\")\n            request.node.add_marker(mark)\n            assert 0\n\n        try:\n            test_func()\n        except Exception as e:\n            assert isinstance(e, AssertionError), \"Test should fail with AssertionError\"",
            "import pytest\n\nclass TestXfailMarker:\n    def test_xfail_marker(self, request):\n        mark = pytest.mark.xfail(reason=\"xfail\")\n        request.node.add_marker(mark)\n        try:\n            assert 0\n        except AssertionError:\n            pytest.xfail(\"xfail\")\n        else:\n            assert False, \"Expected test to fail, but it passed.\"",
            "import pytest\n\nclass TestXfailMarker:\n    def test_xfail_marker(self):\n        def test_func(request):\n            mark = pytest.mark.xfail(reason=\"xfail\")\n            request.node.add_marker(mark)\n            assert 0\n\n        try:\n            test_func()\n            assert False, \"Expected an error but didn't get one\"\n        except Exception as e:\n            assert isinstance(e, AssertionError), \"Expected AssertionError but got a different error\"",
            "import pytest\n\nclass TestDynamicXfail:\n    def test_dynamic_xfail(self):\n        try:\n            @pytest.mark.xfail(reason=\"xfail\")\n            def test_func():\n                assert 0\n            pytest.main(['-rsx', 'test_func'])\n            assert True, \"Test passed without raising an error\"\n        except Exception as e:\n            assert False, f\"Test raised an error: {str(e)}\""
        ]
    }
]